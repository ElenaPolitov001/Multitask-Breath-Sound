{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "09_multitask_sincnet.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Get Google Drive"
      ],
      "metadata": {
        "id": "MBiChxgybLnL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%load_ext autoreload\r\n",
        "from google.colab import drive\r\n",
        "import os\r\n",
        "\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "path = '/content/gdrive/My Drive/Breath-Data/data/training/'\r\n",
        "os.chdir(path)\r\n",
        "!ls"
      ],
      "outputs": [],
      "metadata": {
        "id": "_gX_B2VPjjAa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install tensorflow-gpu --upgrade"
      ],
      "outputs": [],
      "metadata": {
        "id": "iT2-fHwNIT0O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\r\n",
        "print(tf.__version__)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "IP8kw9ZF2BMN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "path_2 = '/content/gdrive/My Drive/Breath-Data/data/training/heavy/*'\r\n",
        "# os.chdir(path_2)\r\n",
        "import glob\r\n",
        "list_file = glob.glob(path_2)\r\n",
        "print(len(list_file))"
      ],
      "outputs": [],
      "metadata": {
        "id": "kGJc_Kc_Ag0V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%matplotlib inline\r\n",
        "import numpy, scipy, matplotlib.pyplot as plt, IPython.display as ipd\r\n",
        "import librosa, librosa.display\r\n",
        "\r\n",
        "x, sr = librosa.load('/content/gdrive/My Drive/Breath-Data/data/training/heavy/05_male_21_NLinh_78_heavy.wav')\r\n",
        "ipd.Audio(x, rate=sr)\r\n",
        "plt.figure(figsize=(15, 5))\r\n",
        "plt.ylabel('Amplitude - Heavy')\r\n",
        "librosa.display.waveplot(x, sr, alpha=0.8)"
      ],
      "outputs": [],
      "metadata": {
        "id": "WYWDxlXddo-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%matplotlib inline\r\n",
        "import numpy, scipy, matplotlib.pyplot as plt, IPython.display as ipd\r\n",
        "import librosa, librosa.display\r\n",
        "\r\n",
        "\r\n",
        "def modified_z_score(intensity):\r\n",
        "    median_int = np.median(intensity)\r\n",
        "    mad_int = np.median([np.abs(intensity - median_int)])\r\n",
        "    modified_z_scores = 0.6745 * (intensity - median_int) / mad_int\r\n",
        "    return modified_z_scores\r\n",
        "\r\n",
        "def fixer(y,m):\r\n",
        "    threshold = 7 # binarization threshold. \r\n",
        "    spikes = abs(np.array(modified_z_score(np.diff(y)))) > threshold\r\n",
        "    y_out = y.copy() # So we donâ€™t overwrite y\r\n",
        "    for i in np.arange(len(spikes)):\r\n",
        "        if spikes[i] != 0: # If we have an spike in position i\r\n",
        "            w = np.arange(i-m,i+1+m) # we select 2 m + 1 points around our spike\r\n",
        "            w2 = w[spikes[w] == 0] # From such interval, we choose the ones which are not spikes\r\n",
        "            y_out[i] = np.mean(y[w2]) # and we average their values\r\n",
        " \r\n",
        "    return y_out\r\n",
        "\r\n",
        "x, sr = librosa.load('/content/gdrive/My Drive/Breath-Data/data/training/heavy/05_male_21_NLinh_78_heavy.wav')\r\n",
        "\r\n",
        "x = fixer(x, 3)\r\n",
        "ipd.Audio(x, rate=sr)\r\n",
        "plt.figure(figsize=(15, 5))\r\n",
        "plt.ylabel('Amplitude - Heavy')\r\n",
        "librosa.display.waveplot(x, sr, alpha=0.8) "
      ],
      "outputs": [],
      "metadata": {
        "id": "XapdttS_1Uvn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x, sr = librosa.load('/content/gdrive/My Drive/Breath-Data/data/training/deep/04_female_21_LAnh_21_deep.wav')\r\n",
        "\r\n",
        "ipd.Audio(x, rate=sr)\r\n",
        "plt.figure(figsize=(15, 5))\r\n",
        "plt.ylabel('Amplitude - deep')\r\n",
        "librosa.display.waveplot(x, sr, alpha=0.8)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9pNPdjixeNvY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x, sr = librosa.load('/content/gdrive/My Drive/Breath-Data/data/training/normal/07_male_21_MQuang_6_normal.wav')\r\n",
        "ipd.Audio(x, rate=sr)\r\n",
        "plt.figure(figsize=(15, 5))\r\n",
        "plt.ylabel('Amplitude - normal')\r\n",
        "librosa.display.waveplot(x, sr, alpha=0.8)"
      ],
      "outputs": [],
      "metadata": {
        "id": "esz8dST5eVtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing data Breath"
      ],
      "metadata": {
        "id": "bChdMRrcTnzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install pydub"
      ],
      "outputs": [],
      "metadata": {
        "id": "aUZGQ5z6WJrx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "import random\r\n",
        "\r\n",
        "from pydub import AudioSegment\r\n",
        "\r\n",
        "duration_breath = 0"
      ],
      "outputs": [],
      "metadata": {
        "id": "KRHAJbILTrLY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_audio_segment (filename, source_path, destination_path, start, end, status, i):\r\n",
        "    \"\"\"[summary]\r\n",
        "    \r\n",
        "    Arguments:\r\n",
        "        filename {[type]} -- [filename of the audio file]\r\n",
        "        source_path {[type]} -- [source of a audio file]\r\n",
        "        destination_path {[type]} -- [destination of a output file]\r\n",
        "        start {[type]} -- [description]\r\n",
        "        end {[type]} -- [description]\r\n",
        "        status {[type]} -- [type of breath]\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    # Pydub works in milliseconds\r\n",
        "    start = start * 1000 \r\n",
        "    end = end * 1000\r\n",
        "    offset_time = (end - start)\r\n",
        "\r\n",
        "    global duration_breath\r\n",
        "    print(offset_time)\r\n",
        "    print(duration_breath)\r\n",
        "\r\n",
        "    if offset_time > duration_breath and offset_time < 5000:\r\n",
        "      duration_breath = offset_time\r\n",
        "    \r\n",
        "    # print(start, end, end_2)\r\n",
        "    \r\n",
        "    # Get the audio file\r\n",
        "    src_Audio = AudioSegment.from_wav(source_path)\r\n",
        "    \r\n",
        "    # Get the audio offset\r\n",
        "    offset_Audio = AudioSegment.from_wav('/content/gdrive/My Drive/Breath-Data/Sine.wav')\r\n",
        "    \r\n",
        "    #Cut the right part\r\n",
        "    output_audio = src_Audio[start:end]\r\n",
        "\r\n",
        "    try:\r\n",
        "      if offset_time > 4000:\r\n",
        "        raise Exception(\"offset_time over 4000\")\r\n",
        "\r\n",
        "      # random start audio\r\n",
        "      rand = random.randint(0, int(3000 - offset_time))\r\n",
        "    \r\n",
        "    \r\n",
        "      #Convert to 5s\r\n",
        "      # output_audio = offset_Audio[0:rand] + output_audio[0:offset_time] + offset_Audio[rand+offset_time+1:3000]\r\n",
        "\r\n",
        "      for j in range(int(end - 4000), int(start), 100):\r\n",
        "        if j < 0:\r\n",
        "          continue\r\n",
        "        output_audio = src_Audio[j:j+4000]\r\n",
        "        # Define name file\r\n",
        "        fname =  filename + \"_\" + str(i) + \"_\" + str(j) + \"_\" + status + '.wav'\r\n",
        "        # print(destination_path)\r\n",
        "        output_audio.export(destination_path + '/' + fname, \r\n",
        "                            format=\"wav\")  # Exports to a wav file in the current path.\r\n",
        "\r\n",
        "      \r\n",
        "      # Define name file\r\n",
        "      # fname =  filename + \"_\" + str(i) + \"_\" + status + '.wav'\r\n",
        "      # print(destination_path)\r\n",
        "      # output_audio.export(destination_path + '/' + fname, \r\n",
        "      #                     format=\"wav\")  # Exports to a wav file in the current path.\r\n",
        "    except Exception as e:\r\n",
        "      print(e)\r\n",
        "      pass"
      ],
      "outputs": [],
      "metadata": {
        "id": "s2_MJN7lWHLk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def split_by_label(source_path, destination_path, label_path, output_folder):\r\n",
        "\r\n",
        "    # Check the output directory status \r\n",
        "\r\n",
        "    check_directory(destination_path, output_folder)\r\n",
        "\r\n",
        "    output_path = os.path.join(destination_path, output_folder) + '/'\r\n",
        "    # Get all the audio files\r\n",
        "    filenames = os.listdir(source_path)\r\n",
        "    \r\n",
        "    meta_data=[[\"\",\"\"]]\r\n",
        "    \r\n",
        "    # Go through all the file \r\n",
        "    for filename in filenames:\r\n",
        "        \r\n",
        "        # take the file name without dot\r\n",
        "        filename =  filename.split(\".\")[0]\r\n",
        "        \r\n",
        "        #get wav file name path\r\n",
        "        wav_path = source_path + filename + \".wav\"\r\n",
        "        \r\n",
        "        #get label filename path\r\n",
        "        csv_path = label_path + filename + \".txt\"\r\n",
        "        \r\n",
        "        #read the label file path \r\n",
        "#         label = pd.read_csv(csv_path, delim_whitespace= True)\r\n",
        "\r\n",
        "        if not os.path.isfile(csv_path):\r\n",
        "            print(\"Not found:\", filename)\r\n",
        "            continue\r\n",
        "\r\n",
        "        # Open the file with read only permit\r\n",
        "        label = open(csv_path, \"r\")\r\n",
        "        # use readlines to read all lines in the file\r\n",
        "        # The variable \"lines\" is a list containing all lines in the file\r\n",
        "        lines = label.readlines()\r\n",
        "        \r\n",
        "#         # split the text\r\n",
        "#         words = text.split()\r\n",
        "        \r\n",
        "        # close the file after reading the lines.\r\n",
        "        label.close()\r\n",
        "        \r\n",
        "        print(csv_path)\r\n",
        "        \r\n",
        "        i = 0\r\n",
        "        \r\n",
        "        #Normal breath\r\n",
        "        for line in lines:\r\n",
        "            breath_start = float(line.split()[0])\r\n",
        "            breath_end   = float(line.split()[1])\r\n",
        "            try:\r\n",
        "                breath = line.split()[2]\r\n",
        "                if breath == 'strong':\r\n",
        "                  breath = 'heavy'\r\n",
        "                if breath == 'normla':\r\n",
        "                  breath = 'normal'\r\n",
        "            except Exception as e:\r\n",
        "                print(e)\r\n",
        "                continue\r\n",
        "            output_by_label = os.path.join(output_path, breath)               \r\n",
        "            if not os.path.exists(output_by_label):\r\n",
        "                os.makedirs(output_by_label)\r\n",
        "            #Export the file\r\n",
        "            get_audio_segment(filename, wav_path, output_by_label, breath_start, breath_end, breath, i)\r\n",
        "            \r\n",
        "            i += 1\r\n",
        "            \r\n",
        "            # Add other label\r\n",
        "            "
      ],
      "outputs": [],
      "metadata": {
        "id": "KuaDtZP6WHQx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Dev set\r\n",
        "DEV_INPUT_PATH = \"/content/gdrive/My Drive/Breath-Data/raw_data/training/\"\r\n",
        "DEV_OUTPUT_PATH = \"/content/gdrive/My Drive/Breath-Data/data/\"\r\n",
        "DEV_LABEL_PATH = \"/content/gdrive/My Drive/Breath-Data/raw_data/training/label/\"\r\n",
        "\r\n",
        "TRAIN_OUTPUT_FOLDER = \"training\"\r\n",
        "TEST_OUTPUT_FOLDER = \"validation\"\r\n",
        "\r\n",
        "\r\n",
        "# Test set\r\n",
        "TEST_INPUT_PATH = \"/content/gdrive/My Drive/Breath-Data/raw_data/validation/\"\r\n",
        "TEST_OUTPUT_PATH = \"/content/gdrive/My Drive/Breath-Data/data/\"\r\n",
        "TEST_LABEL_PATH = \"/content/gdrive/My Drive/Breath-Data/raw_data/validation/label/\"\r\n",
        "\r\n",
        "CHUNK = 5\r\n",
        "OVERLAP = 0.5\r\n",
        "\r\n",
        "LABEL_FOLDER = 'label'\r\n",
        " # Type of breath\r\n",
        "BREATH_TYPE = ['normal', 'deep', 'heavy', 'other']"
      ],
      "outputs": [],
      "metadata": {
        "id": "tbR0k77JWHUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "os.chdir(TEST_LABEL_PATH)\r\n",
        "!ls"
      ],
      "outputs": [],
      "metadata": {
        "id": "FfXgXH8ow4l2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def check_directory(origin_path, folder):\r\n",
        "    directory = os.path.join(origin_path, folder)\r\n",
        "    if not os.path.exists(directory):\r\n",
        "        os.makedirs(directory)"
      ],
      "outputs": [],
      "metadata": {
        "id": "oEBC8L4YWHXL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Training set\r\n",
        "split_by_label(DEV_INPUT_PATH, DEV_OUTPUT_PATH, DEV_LABEL_PATH, TRAIN_OUTPUT_FOLDER)\r\n",
        "\r\n",
        "# Validation set\r\n",
        "split_by_label(TEST_INPUT_PATH, TEST_OUTPUT_PATH, TEST_LABEL_PATH, TEST_OUTPUT_FOLDER)"
      ],
      "outputs": [],
      "metadata": {
        "id": "40ipiZj2WHZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SincConv (slow implementation)\n",
        "Speaker Recognition from Raw Waveform with SincNet\n",
        "Mirco Ravanelli, Yoshua Bengio\n",
        "https://arxiv.org/pdf/1808.00158.pdf"
      ],
      "metadata": {
        "id": "iO83HnXSCvV9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Layer\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "import numpy as np"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ge5hofXDn9mq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\n",
        "import json\r\n",
        "import pickle\r\n",
        "from scipy.io import wavfile\r\n",
        "\r\n",
        "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"0\"\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "with tf.device('/device:GPU:0'):\r\n",
        "\r\n",
        "  import tensorflow.keras as keras\r\n",
        "  import tensorflow as tf\r\n",
        "\r\n",
        "  # Allow memory growth for the GPU\r\n",
        "  # physical_devices = tf.config.experimental.list_physical_devices('GPU')\r\n",
        "  # tf.config.experimental.set_memory_growth(physical_devices, True)\r\n",
        "\r\n",
        "  # from tensorflow.keras.utils import multi_gpu_model\r\n",
        "  # from keras.backend.tensorflow_backend import set_session\r\n",
        "  import librosa\r\n",
        "  from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "  from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "  from tensorflow.keras.utils import to_categorical\r\n",
        "  from tensorflow.keras.models import Sequential\r\n",
        "  from tensorflow.keras.layers import Conv2D, MaxPooling2D\r\n",
        "  from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Permute, Reshape, TimeDistributed\r\n",
        "  from tensorflow.keras.optimizers import Adam\r\n",
        "  from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Flatten\r\n",
        "  from tensorflow.compat.v1.keras.layers import CuDNNLSTM as CuLSTM, CuDNNGRU\r\n",
        "  from tensorflow.keras.layers import add\r\n",
        "  from tensorflow.keras.layers import Input\r\n",
        "  from tensorflow.keras.models import Model\r\n",
        "  from tensorflow.keras.layers import BatchNormalization"
      ],
      "outputs": [],
      "metadata": {
        "id": "dc0QjzkzcuMa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\r\n",
        "from tensorflow.compat.v1 import InteractiveSession\r\n",
        "\r\n",
        "config = ConfigProto()\r\n",
        "config.gpu_options.allow_growth = True\r\n",
        "session = InteractiveSession(config=config)"
      ],
      "outputs": [],
      "metadata": {
        "scrolled": true,
        "id": "v_4KauSgjjAf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class SincConv(Layer):\r\n",
        "    '''\r\n",
        "    Sinc-based convolution Keras layer\r\n",
        "\r\n",
        "    Reference\r\n",
        "    ---------\r\n",
        "    Mirco Ravanelli, Yoshua Bengio,\r\n",
        "    \"Speaker Recognition from raw waveform with SincNet\".\r\n",
        "    https://arxiv.org/abs/1808.00158\r\n",
        "    '''\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def sinc(band, t_right):\r\n",
        "        y_right = K.sin(2 * np.pi * band * t_right) / (2 * np.pi * band * t_right)\r\n",
        "        y_left = K.reverse(y_right, 0)\r\n",
        "        y = K.concatenate([y_left, K.variable(K.ones(1)), y_right])\r\n",
        "        return y\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def hz_to_mel(hz):\r\n",
        "        return 2595.0 * np.log10(1.0 + hz / 700.0)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def mel_to_hz(mels):\r\n",
        "        return 700.0 * (10.0 ** (mels / 2595.0) - 1.0)\r\n",
        "\r\n",
        "    def __init__(self, nb_filters, kernel_size, sample_freq):\r\n",
        "        super(SincConv, self).__init__()\r\n",
        "\r\n",
        "        self.nb_filters = nb_filters\r\n",
        "        self.kernel_size = kernel_size\r\n",
        "        self.sample_freq = sample_freq\r\n",
        "\r\n",
        "        # Set trainable parameters\r\n",
        "        self.b1 = self.add_weight(\r\n",
        "            name='b1',\r\n",
        "            shape=(self.nb_filters,),\r\n",
        "            initializer=\"zeros\",\r\n",
        "            trainable=True)\r\n",
        "        self.band = self.add_weight(\r\n",
        "            name='band',\r\n",
        "            shape=(self.nb_filters,),\r\n",
        "            initializer=\"zeros\",\r\n",
        "            trainable=True)\r\n",
        "        \r\n",
        "        # Initialize weights with cutoff frequencies of the mel-scale filter-bank\r\n",
        "        low_freq_mel = self.hz_to_mel(50)\r\n",
        "        high_freq_mel = self.hz_to_mel(self.sample_freq / 2)\r\n",
        "        mel_points = np.linspace(low_freq_mel, high_freq_mel, num=self.nb_filters)\r\n",
        "        hz_points = self.mel_to_hz(mel_points)\r\n",
        "\r\n",
        "        b1 = np.roll(hz_points, 1)\r\n",
        "        b1[0] = 30\r\n",
        "        b2 = np.roll(hz_points, -1)\r\n",
        "        b2[-1] = (self.sample_freq / 2) - 100\r\n",
        "\r\n",
        "        self.set_weights([b1 / self.sample_freq, (b2 - b1) / self.sample_freq])\r\n",
        "\r\n",
        "        # Initialize weights by 0 and the Nyquist frequency\r\n",
        "        # low = np.zeros(self.nb_filters)\r\n",
        "        # high = np.repeat(self.sample_freq / 2, self.nb_filters)\r\n",
        "        # self.set_weights([low / self.sample_freq,\r\n",
        "        #                   (high - low) / self.sample_freq])\r\n",
        "        \r\n",
        "        # Get beginning and end frequencies of the filters\r\n",
        "        min_freq = 50.0\r\n",
        "        min_band = 50.0\r\n",
        "        self.beg_freq = K.abs(self.b1) + min_freq / self.sample_freq\r\n",
        "        self.end_freq = self.beg_freq + (K.abs(self.band) + min_band / self.sample_freq)\r\n",
        "        \r\n",
        "        t_right_linspace = np.linspace(1, (self.kernel_size - 1) / 2, int((self.kernel_size - 1) / 2))\r\n",
        "        self.t_right = K.variable(t_right_linspace / self.sample_freq)\r\n",
        "\r\n",
        "        # Hamming window\r\n",
        "        n = np.linspace(0, self.kernel_size, num=self.kernel_size)\r\n",
        "        window = 0.54 - 0.46 * K.cos(2 * np.pi * n / self.kernel_size)\r\n",
        "        window = K.cast(window, \"float32\")\r\n",
        "        self.window = K.variable(window)\r\n",
        "\r\n",
        "    def call(self, X):\r\n",
        "        filters = []\r\n",
        "        for i in range(self.nb_filters):\r\n",
        "            low_pass1 = 2 * self.beg_freq[i] * self.sinc(self.beg_freq[i] * self.sample_freq, self.t_right)\r\n",
        "            low_pass2 = 2 * self.end_freq[i] * self.sinc(self.end_freq[i] * self.sample_freq, self.t_right)\r\n",
        "            band_pass = low_pass2 - low_pass1\r\n",
        "            band_pass = band_pass / K.max(band_pass)\r\n",
        "\r\n",
        "            filters.append(band_pass * self.window)\r\n",
        "\r\n",
        "        filters = K.stack(filters)\r\n",
        "\r\n",
        "        # TF convolution assumes data is stored as NWC\r\n",
        "        filters = K.transpose(filters)\r\n",
        "        filters = K.reshape(filters, (self.kernel_size, 1, self.nb_filters))\r\n",
        "\r\n",
        "        return K.conv1d(X, filters)\r\n",
        "\r\n",
        "    def compute_output_shape(self, input_shape):\r\n",
        "        out_width_size = conv_utils.conv_output_length(\r\n",
        "            input_shape[1],\r\n",
        "            self.kernel_size,\r\n",
        "            padding=\"valid\",\r\n",
        "            stride=1,\r\n",
        "            dilation=1)\r\n",
        "        return (input_shape[0], out_width_size, self.nb_filters)\r\n",
        "\r\n",
        "\r\n",
        "X = np.arange(63, dtype=np.single).reshape((1, 63, 1))\r\n",
        "sinc_layer = SincConv(1, 9, 400)\r\n",
        "y = sinc_layer(X)\r\n",
        "print(y.numpy().transpose(0, 2, 1))"
      ],
      "outputs": [],
      "metadata": {
        "id": "0CWp7UYjoMmn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SincConv (fast implementation)"
      ],
      "metadata": {
        "id": "rS6FKCCyCzjF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Layer\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class SincConvFast(Layer):\r\n",
        "    '''\r\n",
        "    Sinc-based convolution Keras layer\r\n",
        "\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    nb_filters : `int`\r\n",
        "        Number of filters (= number of output channels).\r\n",
        "    kernel_size : `int`\r\n",
        "        Convolution filter width/length (will be increased by one if even).\r\n",
        "    sample_freq : `int`\r\n",
        "        Sample rate of input audio.\r\n",
        "    stride : `int`\r\n",
        "        Convolution stride param. Defaults to 1.\r\n",
        "    padding : `string`\r\n",
        "        Convolution padding param. Defaults to \"VALID\".\r\n",
        "    min_low_hz : `int`\r\n",
        "        Minimum lowest frequency for pass band filter. Defaults to 50.\r\n",
        "    min_band_hz : `int`\r\n",
        "        Minimum frequency for pass band filter. Defaults to 50.\r\n",
        "\r\n",
        "    Reference\r\n",
        "    ---------\r\n",
        "    Mirco Ravanelli, Yoshua Bengio,\r\n",
        "    \"Speaker Recognition from raw waveform with SincNet\".\r\n",
        "    https://arxiv.org/abs/1808.00158\r\n",
        "    '''\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def hz_to_mel(hz):\r\n",
        "        return 2595.0 * np.log10(1.0 + hz / 700.0)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def mel_to_hz(mels):\r\n",
        "        return 700.0 * (10.0 ** (mels / 2595.0) - 1.0)\r\n",
        " \r\n",
        " \r\n",
        "    # model.add(SincConvFast(64, 251, sample_frequency, input_shape=(frame_length, 1)))\r\n",
        "    def __init__(self, nb_filters=64, kernel_size=251, sample_freq=8000,\r\n",
        "                 stride=1, padding=\"VALID\", min_low_hz=50, min_band_hz=50,\r\n",
        "                 **kwargs):\r\n",
        "        # super(SincConvFast, self).__init__(**kwargs)\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.nb_filters = nb_filters\r\n",
        "        self.kernel_size = kernel_size\r\n",
        "        self.sample_freq = sample_freq\r\n",
        "        self.stride = stride\r\n",
        "        self.padding = padding\r\n",
        "        self.min_low_hz = min_low_hz\r\n",
        "        self.min_band_hz = min_band_hz\r\n",
        "\r\n",
        "        # Force filter size to be odd for later optimizations with symmetry\r\n",
        "        if kernel_size % 2 == 0:\r\n",
        "            self.kernel_size = self.kernel_size + 1\r\n",
        "\r\n",
        "        # Set trainable parameters\r\n",
        "        self.low_hz = self.add_weight(\r\n",
        "            name='low_hz',\r\n",
        "            shape=(self.nb_filters,),\r\n",
        "            initializer=\"zeros\",\r\n",
        "            trainable=True)\r\n",
        "        self.band_hz = self.add_weight(\r\n",
        "            name='band_hz',\r\n",
        "            shape=(self.nb_filters,),\r\n",
        "            initializer=\"zeros\",\r\n",
        "            trainable=True)\r\n",
        "        \r\n",
        "        # Initialize weights with frequencies of the mel-scale filter-bank\r\n",
        "        low_freq_mel = self.hz_to_mel(30)\r\n",
        "        high_freq_mel = self.hz_to_mel(self.sample_freq / 2 - (self.min_low_hz + self.min_band_hz))\r\n",
        "        mel_points = np.linspace(low_freq_mel, high_freq_mel, num=self.nb_filters + 1)\r\n",
        "        hz_points = self.mel_to_hz(mel_points)\r\n",
        "        self.set_weights([hz_points[:-1], np.diff(hz_points)])\r\n",
        "      \r\n",
        "        # Determine half of t\r\n",
        "        t_linspace = np.arange(-(self.kernel_size - 1) / 2, 0)\r\n",
        "        t = tf.Variable(2 * np.pi * t_linspace / self.sample_freq)\r\n",
        "        t = tf.cast(t, \"float32\")\r\n",
        "        self.t = tf.reshape(t, (1, -1))\r\n",
        "\r\n",
        "        # Determine half of the hamming window\r\n",
        "        n = np.linspace(0, (self.kernel_size / 2) - 1, num=int((self.kernel_size / 2)))\r\n",
        "        window = 0.54 - 0.46 * tf.cos(2 * np.pi * n / self.kernel_size)\r\n",
        "        window = tf.cast(window, \"float32\")\r\n",
        "        self.window = tf.Variable(window)\r\n",
        "\r\n",
        "    def call(self, X):\r\n",
        "        low = self.min_low_hz + tf.abs(self.low_hz)\r\n",
        "        high = tf.clip_by_value(low + self.min_band_hz + tf.abs(self.band_hz), self.min_low_hz, self.sample_freq / 2)\r\n",
        "        band = high - low\r\n",
        "\r\n",
        "        low_times_t = tf.linalg.matmul(tf.reshape(low, (-1, 1)), self.t)\r\n",
        "        high_times_t = tf.linalg.matmul(tf.reshape(high, (-1, 1)), self.t)\r\n",
        "\r\n",
        "        band_pass_left = ((tf.sin(high_times_t) - tf.sin(low_times_t)) / (self.t / 2)) * self.window\r\n",
        "        band_pass_center = tf.reshape(2 * band, (-1, 1))\r\n",
        "        band_pass_right = tf.reverse(band_pass_left, [1])\r\n",
        "\r\n",
        "        filters = tf.concat([band_pass_left,\r\n",
        "                             band_pass_center,\r\n",
        "                             band_pass_right], axis=1)\r\n",
        "        filters = filters / (2 * band[:, None])\r\n",
        "\r\n",
        "        # TF convolution assumes data is stored as NWC\r\n",
        "        filters = tf.transpose(filters)\r\n",
        "        filters = tf.reshape(filters, (self.kernel_size, 1, self.nb_filters))\r\n",
        "\r\n",
        "        return tf.nn.conv1d(X, filters, self.stride, self.padding)\r\n",
        "\r\n",
        "    def compute_output_shape(self, input_shape):\r\n",
        "        out_width_size = conv_utils.conv_output_length(\r\n",
        "            input_shape[1],\r\n",
        "            self.kernel_size,\r\n",
        "            padding=\"valid\",\r\n",
        "            stride=1,\r\n",
        "            dilation=1)\r\n",
        "        return (input_shape[0], out_width_size, self.nb_filters)\r\n",
        "\r\n",
        "\r\n",
        "X = np.arange(63, dtype=np.single).reshape((1, 63, 1))\r\n",
        "sinc_layer = SincConvFast(2, 9, 400)\r\n",
        "y = sinc_layer(X)\r\n",
        "\r\n",
        "print(y.shape)\r\n",
        "\r\n",
        "print(y.numpy().transpose(0, 2, 1))"
      ],
      "outputs": [],
      "metadata": {
        "id": "6MZi_FqkC1k1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Layer\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class SincConvFast_1(Layer):\r\n",
        "    '''\r\n",
        "    Sinc-based convolution Keras layer\r\n",
        "\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    nb_filters : `int`\r\n",
        "        Number of filters (= number of output channels).\r\n",
        "    kernel_size : `int`\r\n",
        "        Convolution filter width/length (will be increased by one if even).\r\n",
        "    sample_freq : `int`\r\n",
        "        Sample rate of input audio.\r\n",
        "    stride : `int`\r\n",
        "        Convolution stride param. Defaults to 1.\r\n",
        "    padding : `string`\r\n",
        "        Convolution padding param. Defaults to \"VALID\".\r\n",
        "    min_low_hz : `int`\r\n",
        "        Minimum lowest frequency for pass band filter. Defaults to 50.\r\n",
        "    min_band_hz : `int`\r\n",
        "        Minimum frequency for pass band filter. Defaults to 50.\r\n",
        "\r\n",
        "    Reference\r\n",
        "    ---------\r\n",
        "    Mirco Ravanelli, Yoshua Bengio,\r\n",
        "    \"Speaker Recognition from raw waveform with SincNet\".\r\n",
        "    https://arxiv.org/abs/1808.00158\r\n",
        "    '''\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def hz_to_mel(hz):\r\n",
        "        return 2595.0 * np.log10(1.0 + hz / 700.0)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def mel_to_hz(mels):\r\n",
        "        return 700.0 * (10.0 ** (mels / 2595.0) - 1.0)\r\n",
        "\r\n",
        "    def __init__(self, nb_filters, kernel_size, sample_freq,\r\n",
        "                 stride=1, padding=\"VALID\", min_low_hz=50, min_band_hz=50,\r\n",
        "                 **kwargs):\r\n",
        "        # super(SincConvFast, self).__init__(**kwargs)\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.nb_filters = nb_filters\r\n",
        "        self.kernel_size = kernel_size\r\n",
        "        self.sample_freq = sample_freq\r\n",
        "        self.stride = stride\r\n",
        "        self.padding = padding\r\n",
        "        self.min_low_hz = min_low_hz\r\n",
        "        self.min_band_hz = min_band_hz\r\n",
        "\r\n",
        "        # Force filter size to be odd for later optimizations with symmetry\r\n",
        "        if kernel_size % 2 == 0:\r\n",
        "            self.kernel_size = self.kernel_size + 1\r\n",
        "\r\n",
        "        # Set trainable parameters\r\n",
        "        self.low_hz = self.add_weight(\r\n",
        "            name='low_hz',\r\n",
        "            shape=(self.nb_filters,),\r\n",
        "            initializer=\"zeros\",\r\n",
        "            trainable=True)\r\n",
        "        self.band_hz = self.add_weight(\r\n",
        "            name='band_hz',\r\n",
        "            shape=(self.nb_filters,),\r\n",
        "            initializer=\"zeros\",\r\n",
        "            trainable=True)\r\n",
        "        \r\n",
        "        # Initialize weights with frequencies of the mel-scale filter-bank\r\n",
        "        low_freq_mel = self.hz_to_mel(30)\r\n",
        "        high_freq_mel = self.hz_to_mel(self.sample_freq / 2 - (self.min_low_hz + self.min_band_hz))\r\n",
        "        mel_points = np.linspace(low_freq_mel, high_freq_mel, num=self.nb_filters + 1)\r\n",
        "        hz_points = self.mel_to_hz(mel_points)\r\n",
        "        self.set_weights([hz_points[:-1], np.diff(hz_points)])\r\n",
        "      \r\n",
        "        # Determine half of t\r\n",
        "        t_linspace = np.arange(-(self.kernel_size - 1) / 2, 0)\r\n",
        "        t = tf.Variable(2 * np.pi * t_linspace / self.sample_freq)\r\n",
        "        t = tf.cast(t, \"float32\")\r\n",
        "        self.t = tf.reshape(t, (1, -1))\r\n",
        "\r\n",
        "        # Determine half of the hamming window\r\n",
        "        n = np.linspace(0, (self.kernel_size / 2) - 1, num=int((self.kernel_size / 2)))\r\n",
        "        window = 0.54 - 0.46 * tf.cos(2 * np.pi * n / self.kernel_size)\r\n",
        "        window = tf.cast(window, \"float32\")\r\n",
        "        self.window = tf.Variable(window)\r\n",
        "\r\n",
        "    def call(self, X):\r\n",
        "        low = self.min_low_hz + tf.abs(self.low_hz)\r\n",
        "        high = tf.clip_by_value(low + self.min_band_hz + tf.abs(self.band_hz), self.min_low_hz, self.sample_freq / 2)\r\n",
        "        band = high - low\r\n",
        "\r\n",
        "        low_times_t = tf.linalg.matmul(tf.reshape(low, (-1, 1)), self.t)\r\n",
        "        high_times_t = tf.linalg.matmul(tf.reshape(high, (-1, 1)), self.t)\r\n",
        "\r\n",
        "        band_pass_left = ((tf.sin(high_times_t) - tf.sin(low_times_t)) / (self.t / 2)) * self.window\r\n",
        "        band_pass_center = tf.reshape(2 * band, (-1, 1))\r\n",
        "        band_pass_right = tf.reverse(band_pass_left, [1])\r\n",
        "\r\n",
        "        filters = tf.concat([band_pass_left,\r\n",
        "                             band_pass_center,\r\n",
        "                             band_pass_right], axis=1)\r\n",
        "        filters = filters / (2 * band[:, None])\r\n",
        "\r\n",
        "        # TF convolution assumes data is stored as NWC\r\n",
        "        filters = tf.transpose(filters)\r\n",
        "        filters = tf.reshape(filters, (self.kernel_size, 1, self.nb_filters))\r\n",
        "\r\n",
        "        return tf.nn.conv1d(X, filters, self.stride, self.padding)\r\n",
        "\r\n",
        "    def compute_output_shape(self, input_shape):\r\n",
        "        out_width_size = conv_utils.conv_output_length(\r\n",
        "            input_shape[1],\r\n",
        "            self.kernel_size,\r\n",
        "            padding=\"valid\",\r\n",
        "            stride=1,\r\n",
        "            dilation=1)\r\n",
        "        return (input_shape[0], out_width_size, self.nb_filters)\r\n",
        "\r\n",
        "\r\n",
        "X = np.arange(63, dtype=np.single).reshape((1, 63, 1))\r\n",
        "sinc_layer = SincConvFast(2, 9, 400)\r\n",
        "y = sinc_layer(X)\r\n",
        "\r\n",
        "print(y.numpy().transpose(0, 2, 1))"
      ],
      "outputs": [],
      "metadata": {
        "id": "64dZQvTIiVOd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers import Layer\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "class SincConvFast_2(Layer):\r\n",
        "    '''\r\n",
        "    Sinc-based convolution Keras layer\r\n",
        "\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    nb_filters : `int`\r\n",
        "        Number of filters (= number of output channels).\r\n",
        "    kernel_size : `int`\r\n",
        "        Convolution filter width/length (will be increased by one if even).\r\n",
        "    sample_freq : `int`\r\n",
        "        Sample rate of input audio.\r\n",
        "    stride : `int`\r\n",
        "        Convolution stride param. Defaults to 1.\r\n",
        "    padding : `string`\r\n",
        "        Convolution padding param. Defaults to \"VALID\".\r\n",
        "    min_low_hz : `int`\r\n",
        "        Minimum lowest frequency for pass band filter. Defaults to 50.\r\n",
        "    min_band_hz : `int`\r\n",
        "        Minimum frequency for pass band filter. Defaults to 50.\r\n",
        "\r\n",
        "    Reference\r\n",
        "    ---------\r\n",
        "    Mirco Ravanelli, Yoshua Bengio,\r\n",
        "    \"Speaker Recognition from raw waveform with SincNet\".\r\n",
        "    https://arxiv.org/abs/1808.00158\r\n",
        "    '''\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def hz_to_mel(hz):\r\n",
        "        return 2595.0 * np.log10(1.0 + hz / 700.0)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def mel_to_hz(mels):\r\n",
        "        return 700.0 * (10.0 ** (mels / 2595.0) - 1.0)\r\n",
        "\r\n",
        "    def __init__(self, nb_filters, kernel_size, sample_freq,\r\n",
        "                 stride=1, padding=\"VALID\", min_low_hz=50, min_band_hz=50,\r\n",
        "                 **kwargs):\r\n",
        "        # super(SincConvFast, self).__init__(**kwargs)\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.nb_filters = nb_filters\r\n",
        "        self.kernel_size = kernel_size\r\n",
        "        self.sample_freq = sample_freq\r\n",
        "        self.stride = stride\r\n",
        "        self.padding = padding\r\n",
        "        self.min_low_hz = min_low_hz\r\n",
        "        self.min_band_hz = min_band_hz\r\n",
        "\r\n",
        "        # Force filter size to be odd for later optimizations with symmetry\r\n",
        "        if kernel_size % 2 == 0:\r\n",
        "            self.kernel_size = self.kernel_size + 1\r\n",
        "\r\n",
        "        # Set trainable parameters\r\n",
        "        self.low_hz = self.add_weight(\r\n",
        "            name='low_hz',\r\n",
        "            shape=(self.nb_filters,),\r\n",
        "            initializer=\"zeros\",\r\n",
        "            trainable=True)\r\n",
        "        self.band_hz = self.add_weight(\r\n",
        "            name='band_hz',\r\n",
        "            shape=(self.nb_filters,),\r\n",
        "            initializer=\"zeros\",\r\n",
        "            trainable=True)\r\n",
        "        \r\n",
        "        # Initialize weights with frequencies of the mel-scale filter-bank\r\n",
        "        low_freq_mel = self.hz_to_mel(30)\r\n",
        "        high_freq_mel = self.hz_to_mel(self.sample_freq / 2 - (self.min_low_hz + self.min_band_hz))\r\n",
        "        mel_points = np.linspace(low_freq_mel, high_freq_mel, num=self.nb_filters + 1)\r\n",
        "        hz_points = self.mel_to_hz(mel_points)\r\n",
        "        self.set_weights([hz_points[:-1], np.diff(hz_points)])\r\n",
        "      \r\n",
        "        # Determine half of t\r\n",
        "        t_linspace = np.arange(-(self.kernel_size - 1) / 2, 0)\r\n",
        "        t = tf.Variable(2 * np.pi * t_linspace / self.sample_freq)\r\n",
        "        t = tf.cast(t, \"float32\")\r\n",
        "        self.t = tf.reshape(t, (1, -1))\r\n",
        "\r\n",
        "        # Determine half of the hamming window\r\n",
        "        n = np.linspace(0, (self.kernel_size / 2) - 1, num=int((self.kernel_size / 2)))\r\n",
        "        window = 0.54 - 0.46 * tf.cos(2 * np.pi * n / self.kernel_size)\r\n",
        "        window = tf.cast(window, \"float32\")\r\n",
        "        self.window = tf.Variable(window)\r\n",
        "\r\n",
        "    def call(self, X):\r\n",
        "        low = self.min_low_hz + tf.abs(self.low_hz)\r\n",
        "        high = tf.clip_by_value(low + self.min_band_hz + tf.abs(self.band_hz), self.min_low_hz, self.sample_freq / 2)\r\n",
        "        band = high - low\r\n",
        "\r\n",
        "        low_times_t = tf.linalg.matmul(tf.reshape(low, (-1, 1)), self.t)\r\n",
        "        high_times_t = tf.linalg.matmul(tf.reshape(high, (-1, 1)), self.t)\r\n",
        "\r\n",
        "        band_pass_left = ((tf.sin(high_times_t) - tf.sin(low_times_t)) / (self.t / 2)) * self.window\r\n",
        "        band_pass_center = tf.reshape(2 * band, (-1, 1))\r\n",
        "        band_pass_right = tf.reverse(band_pass_left, [1])\r\n",
        "\r\n",
        "        filters = tf.concat([band_pass_left,\r\n",
        "                             band_pass_center,\r\n",
        "                             band_pass_right], axis=1)\r\n",
        "        filters = filters / (2 * band[:, None])\r\n",
        "\r\n",
        "        # TF convolution assumes data is stored as NWC\r\n",
        "        filters = tf.transpose(filters)\r\n",
        "        filters = tf.reshape(filters, (self.kernel_size, 1, self.nb_filters))\r\n",
        "\r\n",
        "        return tf.nn.conv1d(X, filters, self.stride, self.padding)\r\n",
        "\r\n",
        "    def compute_output_shape(self, input_shape):\r\n",
        "        out_width_size = conv_utils.conv_output_length(\r\n",
        "            input_shape[1],\r\n",
        "            self.kernel_size,\r\n",
        "            padding=\"valid\",\r\n",
        "            stride=1,\r\n",
        "            dilation=1)\r\n",
        "        return (input_shape[0], out_width_size, self.nb_filters)\r\n",
        "\r\n",
        "\r\n",
        "X = np.arange(63, dtype=np.single).reshape((1, 63, 1))\r\n",
        "sinc_layer = SincConvFast(2, 9, 400)\r\n",
        "y = sinc_layer(X)\r\n",
        "\r\n",
        "print(y.numpy().transpose(0, 2, 1))"
      ],
      "outputs": [],
      "metadata": {
        "id": "YFerlR3EiWHc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\r\n",
        "print(tf.__version__)"
      ],
      "outputs": [],
      "metadata": {
        "id": "fb0BCe16jjAl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install tensorflow==2.2.0"
      ],
      "outputs": [],
      "metadata": {
        "id": "NcUl9nuxEn1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset (BreathSound)\n",
        "\n",
        "**The following preprocessing steps (described in the original article) are not implemented:**\n",
        "\n",
        "- Non-speech intervals at the beginning and end of each sentence were removed\n",
        "- The BreathSound sentences with internal silences lasting more than 125 ms were split into multiple chunks.\n",
        "- For the BreathSound corpus, the training and test material have been randomly selected to exploit 12-15 seconds of training material for each speaker and test sentences lasting 2-6 seconds."
      ],
      "metadata": {
        "id": "GRH6HmKrJO2g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sample_frequency = 8000 # 8kHz (BreathSpeech)\r\n",
        "frame_size = 0.5    # 300ms ~ 0.300\r\n",
        "frame_stride = 0.05      # 10ms\r\n",
        "max_num_frames = 10\r\n",
        "\r\n",
        "frame_length = int(round(frame_size * sample_frequency))\r\n",
        "frame_step = int(round(frame_stride * sample_frequency))\r\n",
        "\r\n",
        "batch_size = 64\r\n",
        "nb_speakers = 3\r\n",
        "\r\n",
        "print(\"Input length: {} ({}s)\".format(frame_length, frame_size * max_num_frames))\r\n",
        "print(\"Input shape: {}\".format((batch_size, frame_length)))"
      ],
      "outputs": [],
      "metadata": {
        "id": "nnsfZXUan9NL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download BreathSound"
      ],
      "metadata": {
        "id": "PzQbs6D3I7na"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#!wget https://www.openslr.org/resources/12/train-clean-100.tar.gz\r\n",
        "#!tar xf train-clean-100.tar.gz"
      ],
      "outputs": [],
      "metadata": {
        "id": "2ToDKo-I9gsY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from IPython.display import Audio\r\n",
        "# Audio('BreathSound/train-clean-100/1081/128618/1081-128618-0012.flac')\r\n",
        "# Audio('breath-deep/data/output/train/01_male_23_BQuyen/normal/01_male_23_BQuyen_0_normal.wav')"
      ],
      "outputs": [],
      "metadata": {
        "id": "I_UOPs22JojW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create BreathSound generator"
      ],
      "metadata": {
        "id": "LH6iTlsLJDCv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.utils import Sequence\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import soundfile as sf\r\n",
        "import glob\r\n",
        "\r\n",
        "def get_frames_indices(filename):\r\n",
        "    signal, fs = sf.read(filename)\r\n",
        "\r\n",
        "    # Determine number of frames\r\n",
        "    signal_length = len(signal)\r\n",
        "    assert signal_length > frame_length\r\n",
        "    num_frames = int(np.floor((signal_length - frame_length) / frame_step))\r\n",
        "\r\n",
        "    # Limit the number of frames\r\n",
        "    num_frames = min(num_frames, max_num_frames)\r\n",
        "\r\n",
        "    return np.arange(0, num_frames * frame_step, frame_step)\r\n",
        "\r\n",
        "def load_dataset(data_folder, max_speakers=10, max_utterances=10):\r\n",
        "    X = []\r\n",
        "    y = []\r\n",
        "\r\n",
        "    files = glob.glob(data_folder)\r\n",
        "#     print(files)\r\n",
        "    for speaker_id in range(min(max_speakers, len(files))):\r\n",
        "#         print(speaker_id)\r\n",
        "#         speaker_files = glob.glob(files[speaker_id] + '/*')\r\n",
        "        speaker_files = glob.glob(files[speaker_id])\r\n",
        "#         print(speaker_files)\r\n",
        "\r\n",
        "        nb_utterances_for_speaker = 0\r\n",
        "\r\n",
        "        for sentence_id in range(len(speaker_files)):\r\n",
        "#             print(speaker_files[sentence_id])\r\n",
        "            sentence_files = glob.glob(speaker_files[sentence_id] + '/*.wav')\r\n",
        "#             print(sentence_files)\r\n",
        "\r\n",
        "            for utterance_id in range(len(sentence_files)):\r\n",
        "                if nb_utterances_for_speaker >= max_utterances:\r\n",
        "                    break\r\n",
        "\r\n",
        "                filename = sentence_files[utterance_id]\r\n",
        "                frames = get_frames_indices(filename)\r\n",
        "\r\n",
        "                for frame in frames:\r\n",
        "                    X.append([filename, frame])\r\n",
        "                    y.append(speaker_id)\r\n",
        "#                     y.append(sentence_id)\r\n",
        "                \r\n",
        "                nb_utterances_for_speaker += 1\r\n",
        "\r\n",
        "    # mean = np.mean(X)\r\n",
        "    # std = np.std(X)\r\n",
        "\r\n",
        "    # X = (X - mean)/std\r\n",
        "    \r\n",
        "    return X, y\r\n",
        "\r\n",
        "class BreathSoundGenerator(Sequence) :\r\n",
        "  \r\n",
        "    def __init__(self, X, y, batch_size):\r\n",
        "        self.X = X\r\n",
        "        self.y = y\r\n",
        "        self.batch_size = batch_size\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        nb_batches = len(self.y) / float(self.batch_size)\r\n",
        "        return np.ceil(nb_batches).astype(np.int)\r\n",
        "  \r\n",
        "    def __getitem__(self, batch_id):\r\n",
        "        X_batch = np.zeros((self.batch_size, frame_length, 1))\r\n",
        "        y_batch = np.zeros(self.batch_size)\r\n",
        "\r\n",
        "        for i in range(self.batch_size):\r\n",
        "            id = batch_id * self.batch_size + i\r\n",
        "            if id >= len(self.y):\r\n",
        "                id = np.random.randint(0, len(self.y))\r\n",
        "\r\n",
        "            path, frame = self.X[id]\r\n",
        "            signal, fs = sf.read(path)\r\n",
        "\r\n",
        "            X_batch[i, :, 0] = signal[frame:frame+frame_length]\r\n",
        "            y_batch[i] = self.y[id]\r\n",
        "\r\n",
        "        return X_batch, y_batch"
      ],
      "outputs": [],
      "metadata": {
        "id": "O3vqAZPEKJAB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load and determine audio filenames and their associated speaker\r\n",
        "X_, y_ = load_dataset(\"/content/gdrive/My Drive/Breath-Data/Users-training/*/*\",\r\n",
        "                    max_speakers=nb_speakers,\r\n",
        "                    max_utterances=8)\r\n",
        "\r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "nb_speakers = 3\r\n",
        "\r\n",
        "# X_, y_ = load_dataset(\"/content/gdrive/My Drive/Breath-Data/data/training/*\",\r\n",
        "#                     max_speakers=nb_speakers,\r\n",
        "#                     max_utterances=8)\r\n",
        "\r\n",
        "X__, y__ = load_dataset(\"/content/gdrive/My Drive/Breath-Data/Users-testing/*/*\",\r\n",
        "                    max_speakers=nb_speakers,\r\n",
        "                    max_utterances=8)\r\n",
        "\r\n",
        "!ls /content/gdrive/My Drive/Breath-Data/data/*\r\n",
        "\r\n",
        "# mean = np.mean(np.array(X_), axis=0)\r\n",
        "# std = np.std(np.array(X_), axis=0)\r\n",
        "\r\n",
        "# X_ = (X_ - mean)/std\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(len(X_), len(y_))\r\n",
        "# Split in train and validation sets\r\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.2)\r\n",
        "X_train, _, y_train, _ = train_test_split(X_, y_, test_size=0.1)\r\n",
        "_, X_val, _, y_val = train_test_split(X__, y__, test_size=0.1)\r\n",
        "\r\n",
        "# normalize the data attributes\r\n",
        "# y_train = preprocessing.normalize(y_train, axis=0)\r\n",
        "# y_val = preprocessing.normalize(y_val, axis=0)\r\n",
        "\r\n",
        "print(y_train)\r\n",
        "print(y_val)\r\n",
        "\r\n",
        "# Instantiate custom generator to load each batch at once\r\n",
        "train_gen = BreathSoundGenerator(X_train, y_train, batch_size)\r\n",
        "print(train_gen)\r\n",
        "val_gen = BreathSoundGenerator(X_val, y_val, batch_size)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2KyP6gcCj3X3",
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(\"Number of training batches:\", len(train_gen))\r\n",
        "print(\"Number of validation batches:\", len(val_gen))"
      ],
      "outputs": [],
      "metadata": {
        "id": "eI7B6INuXX_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SincNet\n",
        "\n",
        "**The model is simplified to avoid overfitting on our subset of BreathSound:**\n",
        "\n",
        "- No LayerNormalization on the input as it prevents the model to converge\n",
        "- The number of filters is reduced\n",
        "- 2 conv layers instead of 3\n",
        "- 2 dense layers instead of 3"
      ],
      "metadata": {
        "id": "u5z2g5U79fgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create model"
      ],
      "metadata": {
        "id": "JR8VsZs7JXk3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, BatchNormalization, LeakyReLU, Flatten, LayerNormalization\r\n",
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "outputs": [],
      "metadata": {
        "id": "PM4SSnAUHOwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KvBlhI9pVDT3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from keras.layers import Input, Dense, Lambda, Layer\r\n",
        "from keras.initializers import Constant\r\n",
        "from keras.models import Model\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "# Custom loss layer\r\n",
        "class CustomMultiLossLayer(Layer):\r\n",
        "    def __init__(self, nb_outputs=2, **kwargs):\r\n",
        "        self.nb_outputs = nb_outputs\r\n",
        "        self.is_placeholder = True\r\n",
        "        super(CustomMultiLossLayer, self).__init__(**kwargs)\r\n",
        "        \r\n",
        "    def build(self, input_shape=None):\r\n",
        "        # initialise log_vars\r\n",
        "        self.log_vars = []\r\n",
        "        for i in range(self.nb_outputs):\r\n",
        "            self.log_vars += [self.add_weight(name='log_var' + str(i), shape=(1,),\r\n",
        "                                              initializer=Constant(0.), trainable=True)]\r\n",
        "        super(CustomMultiLossLayer, self).build(input_shape)\r\n",
        "\r\n",
        "    def multi_loss(self, ys_true, ys_pred):\r\n",
        "        assert len(ys_true) == self.nb_outputs and len(ys_pred) == self.nb_outputs\r\n",
        "        loss = 0\r\n",
        "        for y_true, y_pred, log_var in zip(ys_true, ys_pred, self.log_vars):\r\n",
        "            precision = K.exp(-log_var[0])\r\n",
        "            loss += K.sum(precision * (y_true - y_pred)**2. + log_var[0], -1)\r\n",
        "        return K.mean(loss)\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        ys_true = inputs[:self.nb_outputs]\r\n",
        "        ys_pred = inputs[self.nb_outputs:]\r\n",
        "        loss = self.multi_loss(ys_true, ys_pred)\r\n",
        "        self.add_loss(loss, inputs=inputs)\r\n",
        "        # We won't actually use the output.\r\n",
        "        return K.concatenate(inputs, -1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2-lcotvauy-A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "# %tensorflow_version 2.x\r\n",
        "\r\n",
        "from tensorflow.keras.models import Model, Sequential\r\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense, DepthwiseConv2D, GlobalAveragePooling2D, Input\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.layers import Conv1D as conv1_1\r\n",
        "from tensorflow.keras.layers import Conv1D as conv1_2\r\n",
        "from tensorflow.keras.layers import Conv1D as conv1_3\r\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Flatten\r\n",
        "from keras.layers.merge import add\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "\r\n",
        "INPUT_SHAPE = (frame_length, 1)\r\n",
        "\r\n",
        "class MultiTaskLossFunctionNet(object):\r\n",
        "\r\n",
        "  def _linear_basenetwork(inputs, classes = nb_speakers, finAct = 'linear'):\r\n",
        "    x = SincConvFast_1(64, 251, sample_frequency)(inputs)\r\n",
        "    # x = conv1_2(filters=64, kernel_size=251)(inputs)\r\n",
        "    x = MaxPooling1D(pool_size=3)(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv1D(filters=32, kernel_size=5)(x)\r\n",
        "    x = MaxPooling1D(pool_size=3)(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Flatten()(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "\r\n",
        "    x = Dense(64)(x)\r\n",
        "    x = BatchNormalization(momentum=0.05)(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Dense(64)(x)\r\n",
        "    x = BatchNormalization(momentum=0.05)(x)\r\n",
        "    x = LeakyReLU(name='layer_features_1', alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Dense(nb_speakers)(x)\r\n",
        "    x = Activation(finAct, name='output_1')(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "  def _relu_basenetwork(inputs, classes = nb_speakers, finAct = 'sigmoid'):\r\n",
        "    x = SincConvFast_1(64, 251, sample_frequency)(inputs)\r\n",
        "    # x = conv1_2(filters=64, kernel_size=251)(inputs)\r\n",
        "    x = MaxPooling1D(pool_size=3)(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv1D(filters=32, kernel_size=5)(x)\r\n",
        "    x = MaxPooling1D(pool_size=3)(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Flatten()(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "\r\n",
        "    x = Dense(64)(x)\r\n",
        "    x = BatchNormalization(momentum=0.05)(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Dense(64)(x)\r\n",
        "    x = BatchNormalization(momentum=0.05)(x)\r\n",
        "    x = LeakyReLU(name='layer_features_2', alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Dense(nb_speakers)(x)\r\n",
        "    x = Activation(finAct, name='output_2')(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "  def _softmax_basenetwork(inputs, classes = nb_speakers, finAct = 'softmax'):\r\n",
        "    x = SincConvFast_2(64, 251, sample_frequency, input_shape=(frame_length, 1))(inputs)\r\n",
        "    # x = conv1_3(filters=64, kernel_size=251)(inputs)\r\n",
        "    x = MaxPooling1D(pool_size=3)(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv1D(filters=32, kernel_size=5)(x)\r\n",
        "    x = MaxPooling1D(pool_size=3)(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Flatten()(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "\r\n",
        "    x = Dense(64)(x)\r\n",
        "    x = BatchNormalization(momentum=0.05)(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Dense(64)(x)\r\n",
        "    x = BatchNormalization(momentum=0.05)(x)\r\n",
        "    x = LeakyReLU(name='layer_features_3', alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Dense(nb_speakers)(x)\r\n",
        "    x = Activation(finAct, name='output_3')(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "  def basenetwork():\r\n",
        "    inputs = Input(shape=INPUT_SHAPE)\r\n",
        "    x = SincConvFast_2(64, 251, sample_frequency, input_shape=(frame_length, 1))(inputs)\r\n",
        "    x = MaxPooling1D(pool_size=3)(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv1D(filters=32, kernel_size=5)(x)\r\n",
        "    x = MaxPooling1D(pool_size=3)(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Flatten()(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "\r\n",
        "    x = Dense(64)(x)\r\n",
        "    x = BatchNormalization(momentum=0.05)(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Dense(64)(x)\r\n",
        "    x = BatchNormalization(momentum=0.05)(x)\r\n",
        "    x = LeakyReLU(name='layer_features_3', alpha=0.2)(x)\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "  def basenetwork_lstm():\r\n",
        "    inputs = Input(shape=INPUT_SHAPE)\r\n",
        "    x = SincConvFast_2(64, 251, sample_frequency, input_shape=(frame_length, 1))(inputs)\r\n",
        "    \r\n",
        "    z1 = Bidirectional(CuLSTM(128, return_sequences=True))(x)\r\n",
        "    z2 = Bidirectional(CuLSTM(units=128, return_sequences=True))(z1)\r\n",
        "    z3 = add([z1, z2])  # residual connection\r\n",
        "    z4 = Bidirectional(CuLSTM(units=128, return_sequences=True))(z3)\r\n",
        "    z5 = Bidirectional(CuLSTM(units=128, return_sequences=False))(z4)\r\n",
        "    z6 = add([z4, z5])  # residual connection    \r\n",
        "    z61 = Flatten()(z6)        \r\n",
        "    z7 = Dense(256, activation='relu')(z61)\r\n",
        "    z8 = Dropout(0.5)(z7)\r\n",
        "    \r\n",
        "    return z8\r\n",
        "\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def build(inputShape=INPUT_SHAPE, numGender = nb_speakers, numRace = nb_speakers):\r\n",
        "    inputs = Input(shape=INPUT_SHAPE)\r\n",
        "    x = SincConvFast_2(64, 251, sample_frequency, input_shape=(frame_length, 1))(inputs)\r\n",
        "\r\n",
        "    ##########################\r\n",
        "    z1 = Bidirectional(CuLSTM(128, return_sequences=True))(x)\r\n",
        "    z2 = Bidirectional(CuLSTM(units=128, return_sequences=True))(z1)\r\n",
        "    z3 = add([z1, z2])  # residual connection\r\n",
        "    z4 = Bidirectional(CuLSTM(units=128, return_sequences=True))(z3)\r\n",
        "    z5 = Bidirectional(CuLSTM(units=128, return_sequences=False))(z4)\r\n",
        "    z6 = add([z4, z5])  # residual connection    \r\n",
        "    z61 = Flatten()(z6)        \r\n",
        "    z7 = Dense(256, activation='relu')(z61)\r\n",
        "    z8 = Dropout(0.5)(z7)\r\n",
        "    ##########################\r\n",
        "\r\n",
        "    x = MaxPooling1D(pool_size=3)(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Conv1D(filters=32, kernel_size=5)(x)\r\n",
        "    x = MaxPooling1D(pool_size=3)(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Flatten()(x)\r\n",
        "    x = LayerNormalization()(x)\r\n",
        "\r\n",
        "    x = Dense(64)(x)\r\n",
        "    x = BatchNormalization(momentum=0.05)(x)\r\n",
        "    x = LeakyReLU(alpha=0.2)(x)\r\n",
        "\r\n",
        "    x = Dense(64)(x)\r\n",
        "    x = BatchNormalization(momentum=0.05)(x)\r\n",
        "    x = LeakyReLU(name='layer_features_3', alpha=0.2)(x)\r\n",
        "\r\n",
        "\r\n",
        "    # linearBranch=MultiTaskLossFunctionNet._linear_basenetwork(inputs=inputs,\r\n",
        "    #   classes=nb_speakers, finAct='softmax') # linear\r\n",
        "    # reluBranch=MultiTaskLossFunctionNet._relu_basenetwork(inputs=inputs,\r\n",
        "    #   classes = numGender, finAct='softmax') # relu\r\n",
        "    # softmaxBranch=MultiTaskLossFunctionNet._softmax_basenetwork(inputs=inputs,\r\n",
        "    #   classes = numRace, finAct='softmax')\r\n",
        "    \r\n",
        "    # Dung chung 1 model\r\n",
        "    branch_1 = Dense(nb_speakers, activation='softmax', name='output_1')(x) \r\n",
        "    branch_2 = Dense(nb_speakers, activation='sigmoid', name='output_2')(x) \r\n",
        "    branch_3 = Dense(nb_speakers, activation='softmax', name='output_3')(x) \r\n",
        "    branch_4 = Dense(nb_speakers, activation='softmax', name='output_4')(z8) \r\n",
        "    # branch_4 = Dense(nb_speakers, activation='softmax', name='output_4')(x)\r\n",
        "    # branch_5 = Dense(nb_speakers, activation='softmax', name='output_5')(x)  \r\n",
        "\r\n",
        "\r\n",
        "    # Táº¡o má»™t mÃ´ hÃ¬nh sá»­ dá»¥ng Ä‘áº§u vÃ o lÃ  má»™t batch loss function, sau Ä‘Ã³ mÃ´ hÃ¬nh sáº½ \r\n",
        "    # ráº½ nhÃ¡nh, má»™t nhÃ¡nh xÃ¡c Ä‘á»‹nh Ä‘áº·c trÆ°ng cá»§a colors vÃ  má»™t nhÃ¡nh xÃ¡c Ä‘á»‹nh Ä‘áº·c trÆ°ng cá»§a fashion\r\n",
        "    model = Model(\r\n",
        "      inputs=inputs,\r\n",
        "      # outputs=[linearBranch, reluBranch, softmaxBranch],\r\n",
        "      outputs=[branch_1, \r\n",
        "               branch_2, \r\n",
        "               branch_3, \r\n",
        "               branch_4, \r\n",
        "              #  branch_5\r\n",
        "               ],\r\n",
        "      name=\"multitask_net\")\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "model_multi = MultiTaskLossFunctionNet.build(inputShape=INPUT_SHAPE)\r\n",
        "model_multi.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "nVF9u8Xk-ROz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(model_multi.metrics_names)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VyGnT3vOnnmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model - Multitask Sincnet CNN"
      ],
      "metadata": {
        "id": "f7gwrKJxJao5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def masked_loss_function(y_true, y_pred):\r\n",
        "    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\r\n",
        "    return K.categorical_crossentropy(y_true * mask, y_pred * mask)"
      ],
      "outputs": [],
      "metadata": {
        "id": "OeS9tSO77Zbu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.losses import mean_squared_error, binary_crossentropy, sparse_categorical_crossentropy\r\n",
        "from tensorflow.keras.metrics import kl_divergence\r\n",
        "\r\n",
        "def kl_crossentropy(y_true, y_pred):\r\n",
        "    kl = kl_divergence(y_true, y_pred)\r\n",
        "    crossentropy = sparse_categorical_crossentropy(y_true, y_pred)\r\n",
        "    return kl + crossentropy\r\n",
        "\r\n",
        "\r\n",
        "def mse_crossentropy(y_true, y_pred):\r\n",
        "    mse = mean_squared_error(y_true, y_pred)\r\n",
        "    crossentropy = sparse_categorical_crossentropy(y_true, y_pred)\r\n",
        "    return ((mse + crossentropy)/2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "a6-CqyZzV_Pb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# import tensorflow_addons as tfa\r\n",
        "\r\n",
        "losses = {\r\n",
        "\t# \"output_1\": \"poisson\",\r\n",
        "  # \"output_1\": \"mse\",\r\n",
        "  \"output_1\": \"sparse_categorical_crossentropy\",\r\n",
        "\t# \"output_2\": \"cosine_similarity\",\r\n",
        "  # \"output_2\": \"center_loss\",\r\n",
        "  # \"output_2\": mean_squared_error, # accuracy low\r\n",
        "  \"output_2\": \"poisson\",\r\n",
        "\t\"output_3\": mse_crossentropy,\r\n",
        "  \"output_4\": \"sparse_categorical_crossentropy\",\r\n",
        "  # \"output_5\": \"sparse_categorical_crossentropy\",\r\n",
        "}\r\n",
        "\r\n",
        "lossWeights = {\"output_1\": 3000, \r\n",
        "               \"output_2\": 3000, \r\n",
        "               \"output_3\": 3000, \r\n",
        "               \"output_4\": 1.0, \r\n",
        "              #  \"output_5\": 1000.0\r\n",
        "               }\r\n",
        "model_multi.compile(loss=losses, loss_weights= lossWeights, optimizer=RMSprop(lr=0.001), metrics=['accuracy'])\r\n",
        "\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "whoDF109PlZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not os.path.exists('checkpoints'):\r\n",
        "\tos.mkdir('checkpoints')\r\n",
        "checkpoint_path = \"./checkpoints/training-{epoch:04d}.ckpt\"\r\n",
        "save_callback = ModelCheckpoint(filepath=checkpoint_path,\r\n",
        "                                save_best_only=True,\r\n",
        "                                save_weights_only=True,\r\n",
        "                                verbose=1)\r\n",
        "\r\n",
        "history = model_multi.fit(train_gen,\r\n",
        "                            validation_data=val_gen,\r\n",
        "                            epochs=100,\r\n",
        "                            initial_epoch=0,\r\n",
        "                            callbacks=[save_callback]\r\n",
        "                          )"
      ],
      "outputs": [],
      "metadata": {
        "id": "6u2q5FuhS24l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate model"
      ],
      "metadata": {
        "id": "3SSLGXtTJcFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss and accuracy"
      ],
      "metadata": {
        "id": "G9IPXvMMVy7P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# FIXME: Evaluating a generator returns different results at every call.\r\n",
        "\r\n",
        "val_accuracy = model_multi.evaluate(val_gen)\r\n",
        "\r\n",
        "# print(\"Loss on validation set:\", val_loss)\r\n",
        "print(\"Accuracy on validation set:\", val_accuracy)"
      ],
      "outputs": [],
      "metadata": {
        "id": "1PSs2bcsF9va"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(history.history['output_3_accuracy'])\r\n",
        "plt.plot(history.history['val_output_3_accuracy'])\r\n",
        "plt.title('Model accuracy over epochs')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "gPMKotUQhETT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# !pip install matplotlib"
      ],
      "outputs": [],
      "metadata": {
        "id": "jo0wy244jjAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix and metrics"
      ],
      "metadata": {
        "id": "FT_H0-rpxuF3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load all batches of validation generator in memory\r\n",
        "\r\n",
        "nb_batches = len(val_gen)\r\n",
        "X_val = np.empty((nb_batches, batch_size, frame_length, 1))\r\n",
        "y_val = np.empty((nb_batches, batch_size))\r\n",
        "\r\n",
        "for i in range(nb_batches):\r\n",
        "    X_val[i], y_val[i] = val_gen.__getitem__(i)\r\n",
        "\r\n",
        "X_val = X_val.reshape((nb_batches * batch_size, -1))\r\n",
        "y_val = y_val.reshape(nb_batches * batch_size)\r\n",
        "\r\n",
        "y_val_actual = np.argmax(model_multi.predict(X_val), axis=-1)\r\n",
        "print(y_val)\r\n",
        "print(y_val_actual)"
      ],
      "outputs": [],
      "metadata": {
        "id": "XrsRyjaxs8B7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\r\n",
        "\r\n",
        "# https://en.wikipedia.org/wiki/Precision_and_recall\r\n",
        "\r\n",
        "p, r, f1, _ = precision_recall_fscore_support(y_val,\r\n",
        "                                              y_val_actual[0], # outcome have 3 y_vals\r\n",
        "                                              average='macro',\r\n",
        "                                              zero_division=0)\r\n",
        "\r\n",
        "# print(y_val)\r\n",
        "# print(y_val_actual)\r\n",
        "\r\n",
        "print(\"Precision:\", p)\r\n",
        "print(\"Recall:\", r)\r\n",
        "print(\"F1 score:\", f1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "rIVtpDSlwWQq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn import metrics\r\n",
        "\r\n",
        "# Print the precision and recall, among other metrics\r\n",
        "print(metrics.classification_report(y_val, y_val_actual[0], digits=3))"
      ],
      "outputs": [],
      "metadata": {
        "id": "v-px60A_jjAv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from mlxtend.plotting import plot_confusion_matrix\r\n",
        "\r\n",
        "cm = confusion_matrix(y_val, y_val_actual[0])\r\n",
        "\r\n",
        "plot_confusion_matrix(cm,\r\n",
        "                      show_normed=True,\r\n",
        "                      show_absolute=False,\r\n",
        "                      figsize=(10, 10),\r\n",
        "                      hide_ticks=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "eRAvRfgGzLij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model BiLSTM "
      ],
      "metadata": {
        "id": "oNlOyhJDjjAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Pre-Procceing Data"
      ],
      "metadata": {
        "id": "z5RNsa9rPKf-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install playsound"
      ],
      "outputs": [],
      "metadata": {
        "id": "SOEVFCyBKk3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import librosa\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import itertools\r\n",
        "from playsound import playsound\r\n",
        "from random import shuffle\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from librosa.feature import melspectrogram\r\n",
        "from librosa.util import normalize\r\n",
        "from librosa.display import waveplot"
      ],
      "outputs": [],
      "metadata": {
        "id": "jjmvqwurPKO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Data library\r\n",
        "\r\n",
        "heavyData = '/content/gdrive/My Drive/Breath-Data/Training-Data/heavy/'\r\n",
        "otherData = '/content/gdrive/My Drive/Breath-Data/Training-Data/other/'\r\n",
        "deepData = '/content/gdrive/My Drive/Breath-Data/Training-Data/deep/'\r\n",
        "normalData = '/content/gdrive/My Drive/Breath-Data/Training-Data/normal/'"
      ],
      "outputs": [],
      "metadata": {
        "id": "7eBhZICYKjKt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# os.chdir(heavyData)\r\n",
        "# !ls"
      ],
      "outputs": [],
      "metadata": {
        "id": "MVbQE7qoKjN9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Read original data\r\n",
        "\r\n",
        "def readCoughData(file):\r\n",
        "    origData,origSampFreq = librosa.load(file, sr=None)\r\n",
        "    return origData, origSampFreq"
      ],
      "outputs": [],
      "metadata": {
        "id": "nlbQ-bkAKjRa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# resample original data to 16000 Khz\r\n",
        "\r\n",
        "def resample(originalData, origSampFreq, targetSampFreq):\r\n",
        "    resampledData = librosa.resample(originalData, origSampFreq, targetSampFreq)\r\n",
        "    return resampledData"
      ],
      "outputs": [],
      "metadata": {
        "id": "sE6Z3ehLKjU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Normalize Sound Data\r\n",
        "\r\n",
        "def normalizeSound(resampledData, axis):\r\n",
        "    \"\"\" Axis is 0 for row-wise and 1 \r\n",
        "    for column wise\"\"\"\r\n",
        "    normalizedData = normalize(resampledData, axis)\r\n",
        "    return normalizedData"
      ],
      "outputs": [],
      "metadata": {
        "id": "_gLHpnipKjXs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Calculate Mel-Spectogram\r\n",
        "\r\n",
        "def calculateMelSpectogram(normalizedData, hop_length, win_length, sr):\r\n",
        "    #newSamplingFreq = 16000\r\n",
        "    S=librosa.feature.melspectrogram(normalizedData, sr=sr, hop_length=hop_length, win_length=win_length)\r\n",
        "    return S"
      ],
      "outputs": [],
      "metadata": {
        "id": "Fr4K4UPEKjbY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# plot orginal time domain data\r\n",
        "\r\n",
        "def plotSound(soundData, sr, x_axis_string):\r\n",
        "    waveplot(soundData, sr, x_axis=x_axis_string)"
      ],
      "outputs": [],
      "metadata": {
        "id": "UbwPYHFnKje2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Plot melspectogram\r\n",
        "\r\n",
        "def plotMelSpectogram(S, sr, ref=np.max):\r\n",
        "    plt.figure(figsize=(10, 4))\r\n",
        "    S_dB = librosa.power_to_db(S, ref=np.max)\r\n",
        "    librosa.display.specshow(S_dB, x_axis='time',y_axis='mel', sr=16000,)\r\n",
        "    plt.colorbar(format='%+2.0f dB')\r\n",
        "    plt.title('Mel-frequency spectrogram')\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "IBjFYG1QMPsK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def featureExtraction(audioFile, targetSampFreq, axis, hop_length,win_length):\r\n",
        "    y, y_sr = readCoughData(file=audioFile)\r\n",
        "    print(y, y_sr)\r\n",
        "    resampledData = resample(originalData=y, origSampFreq=y_sr, targetSampFreq=targetSampFreq)\r\n",
        "    normalizedData = normalizeSound(resampledData, axis=axis)\r\n",
        "    S = calculateMelSpectogram(normalizedData=normalizedData, hop_length=hop_length, win_length=win_length, sr=targetSampFreq)\r\n",
        "    plotSound(soundData=normalizedData, sr=targetSampFreq,x_axis_string='time')\r\n",
        "    plotMelSpectogram(S, sr=targetSampFreq, ref=np.max)\r\n",
        "    return S"
      ],
      "outputs": [],
      "metadata": {
        "id": "rLBpSkg3MPu_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\r\n",
        "import h5py\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from tensorflow.python.keras import backend as K\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Dense, Activation, Flatten, Dropout, Input\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop"
      ],
      "outputs": [],
      "metadata": {
        "id": "hU6Z-Rl5MPyH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def cough_detection_model():\r\n",
        "    input_layer = Input((432,228,1))\r\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(input_layer)\r\n",
        "    x = Conv2D(filters=32,kernel_size=(5,5),padding='same')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "    x = Conv2D(filters=32,kernel_size=(5,5),padding='same')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(input_layer)\r\n",
        "    x = Flatten()(x)\r\n",
        "    x = Dense(128)(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = Dropout(0.5)(x)\r\n",
        "    x = Dense(128)(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = Dropout(0.5)(x)\r\n",
        "    output_layer = Dense(2,activation = 'softmax')(x)\r\n",
        "    model = Model(inputs=input_layer,outputs=output_layer)\r\n",
        "    adam = Adam(lr=0.0001)\r\n",
        "    model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\r\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "aW9Bj1gaMP0i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# def one_hot(a):\r\n",
        "#     b = np.zeros((a.size, a.max()+1))\r\n",
        "#     b[np.arange(a.size),a] = 1\r\n",
        "#     return b\r\n",
        "# X_train =                         # load your data here shape (80,100,50)\r\n",
        "# X_train = X_train.reshape((80,100,50,1))\r\n",
        "# y_train =                         # load your labels here shape (80,1)\r\n",
        "# y_train = one_hot(y_train)                       # one_hot_encoding\r\n",
        "# number_of_epochs = 50 # number of times you fed each data on X_train to the model\r\n",
        "# #model = cough_detection_model() # here you have to call the model you want to use, in this case DL_MC\r\n",
        "# model = cough_detection_model()\r\n",
        "# print('# Fit model on training data')\r\n",
        "# history = model.fit(X_train, y_train,\r\n",
        "#                     batch_size = 4,\r\n",
        "#                     epochs = number_of_epochs, validation_data = (X_train,y_train)) #I have set same data for training and\r\n",
        "#                                                 # for validation because we have few instances, later when we have\r\n",
        "#                                                 #more data we will make an split train/validation/test\r\n",
        "# print('\\nhistory dict:', history.history)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Kgw87KnnMP3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Import Library "
      ],
      "metadata": {
        "id": "honw9yXVPTSt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\n",
        "import json\r\n",
        "import pickle\r\n",
        "from scipy.io import wavfile\r\n",
        "\r\n",
        "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"0\"\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "with tf.device('/device:GPU:0'):\r\n",
        "\r\n",
        "    import tensorflow.keras as keras\r\n",
        "    import tensorflow as tf\r\n",
        "\r\n",
        "# Allow memory growth for the GPU\r\n",
        "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\r\n",
        "# tf.config.experimental.set_memory_growth(physical_devices, True)\r\n",
        "\r\n",
        "# from tensorflow.keras.utils import multi_gpu_model\r\n",
        "# from keras.backend.tensorflow_backend import set_session\r\n",
        "    import librosa\r\n",
        "    from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "    from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "    from tensorflow.keras.utils import to_categorical\r\n",
        "    from tensorflow.keras.models import Sequential\r\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPooling2D\r\n",
        "    from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Permute, Reshape, TimeDistributed\r\n",
        "    from tensorflow.keras.optimizers import Adam\r\n",
        "    from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Flatten\r\n",
        "    from tensorflow.compat.v1.keras.layers import CuDNNLSTM as CuLSTM\r\n",
        "    from tensorflow.compat.v1.keras.layers import Input, Dense, Lambda, Layer\r\n",
        "    from tensorflow.keras.layers import add\r\n",
        "    from tensorflow.keras.layers import Input\r\n",
        "    from tensorflow.keras.models import Model\r\n",
        "    from tensorflow.keras.layers import BatchNormalization\r\n",
        "    from tensorflow.keras.layers.experimental import preprocessing\r\n",
        "\r\n",
        "    normalize = preprocessing.Normalization()\r\n",
        "# from keras.utils import multi_gpu_model\r\n",
        "\r\n",
        "# from LSTM_MODEL import LSTM_MODEL\r\n",
        "# from dataset import BreathDataGenerator\r\n",
        "\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "_gY6jU5fjjAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Init model"
      ],
      "metadata": {
        "id": "fa5KX9ozPoQk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from keras.layers import Input, Dense, Lambda, Layer\r\n",
        "from tensorflow.keras.initializers import Constant\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "# Custom loss layer\r\n",
        "class CustomMultiLossLayer(tf.compat.v1.keras.layers.Layer):\r\n",
        "    def __init__(self, nb_outputs=2, **kwargs):\r\n",
        "        self.nb_outputs = nb_outputs\r\n",
        "        self.is_placeholder = True\r\n",
        "        super(CustomMultiLossLayer, self).__init__(**kwargs)\r\n",
        "        \r\n",
        "    def build(self, input_shape=None):\r\n",
        "        # initialise log_vars\r\n",
        "        self.log_vars = []\r\n",
        "        for i in range(self.nb_outputs):\r\n",
        "            self.log_vars += [self.add_weight(name='log_var' + str(i), shape=(1,),\r\n",
        "                                              initializer=Constant(0.), trainable=True)]\r\n",
        "        super(CustomMultiLossLayer, self).build(input_shape)\r\n",
        "\r\n",
        "    def multi_loss(self, ys_true, ys_pred):\r\n",
        "        # print(self.nb_outputs)\r\n",
        "        # print(len(ys_true))\r\n",
        "        # print(len(ys_pred))\r\n",
        "        # print(ys_true)\r\n",
        "        # print(ys_pred)\r\n",
        "        assert len(ys_true) == self.nb_outputs and len(ys_pred) == self.nb_outputs\r\n",
        "        loss = 0\r\n",
        "        for y_true, y_pred, log_var in zip(ys_true, ys_pred, self.log_vars):\r\n",
        "            precision = K.exp(-log_var[0])\r\n",
        "            loss += K.sum(precision * (y_true - y_pred)**2. + log_var[0], -1)\r\n",
        "        return K.mean(loss)\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        ys_true = inputs[:self.nb_outputs]\r\n",
        "        ys_pred = inputs[self.nb_outputs:]\r\n",
        "        loss = self.multi_loss(ys_true, ys_pred)\r\n",
        "        self.add_loss(loss, inputs=inputs)\r\n",
        "        # We won't actually use the output.\r\n",
        "        return K.concatenate(inputs, -1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SS8o5Gvp0O9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from tensorflow.python.framework.ops import disable_eager_execution\r\n",
        "# disable_eager_execution()\r\n",
        "\r\n",
        "def get_prediction_model(classes):\r\n",
        "\r\n",
        "    # inp = Input(shape=INPUT_SIZE, name='inp') \r\n",
        "    input = Input(shape=(3,32,251), name='inp') \r\n",
        "\r\n",
        "    # inputs = Input(shape=INPUT_SHAPE)\r\n",
        "    # x = SincConvFast_2(64, 251, sample_frequency, input_shape=(frame_length, 1))(inp)\r\n",
        "    \r\n",
        "    z1 = Bidirectional(CuLSTM(128, return_sequences=True))(inp)\r\n",
        "    z2 = Bidirectional(CuLSTM(units=128, return_sequences=True))(z1)\r\n",
        "    z3 = add([z1, z2])  # residual connection\r\n",
        "    z4 = Bidirectional(CuLSTM(units=128, return_sequences=True))(z3)\r\n",
        "    z5 = Bidirectional(CuLSTM(units=128, return_sequences=False))(z4)\r\n",
        "    z6 = add([z4, z5])  # residual connection    \r\n",
        "    z61 = Flatten()(z6)        \r\n",
        "    z7 = Dense(256, activation='relu')(z61)\r\n",
        "    z8 = Dropout(0.5)(z7)\r\n",
        "\r\n",
        "    out = Dense(classes, activation='softmax')(z7)\r\n",
        "\r\n",
        "    y1_pred = Dense(classes, activation='relu', name='output_1')(out)\r\n",
        "    y2_pred = Dense(classes, activation='relu', name='output_2')(out)\r\n",
        "\r\n",
        "    model  = Model(inp, [y1_pred, y2_pred])\r\n",
        "\r\n",
        "    model.summary()\r\n",
        "\r\n",
        "    return model\r\n",
        "    # return y1_pred, y2_pred\r\n",
        "\r\n",
        "def get_trainable_model(data_input_shape, classes, learning_rate):\r\n",
        "    # data_input_shape=INPUT_SIZE\r\n",
        "    # classes=N_CLASSES\r\n",
        "    # learning_rate=0.001\r\n",
        "    \r\n",
        "    inp = Input(shape=data_input_shape, name='inp')\r\n",
        "    # inp = input[0]\r\n",
        "\r\n",
        "    z1 = Bidirectional(CuLSTM(128, return_sequences=True))(inp)\r\n",
        "    z2 = Bidirectional(CuLSTM(units=128, return_sequences=True))(z1)\r\n",
        "    z3 = add([z1, z2])  # residual connection\r\n",
        "    z4 = Bidirectional(CuLSTM(units=128, return_sequences=True))(z3)\r\n",
        "    z5 = Bidirectional(CuLSTM(units=128, return_sequences=False))(z4)\r\n",
        "    z6 = add([z4, z5])  # residual connection    \r\n",
        "    z61 = Flatten()(z6)        \r\n",
        "    z7 = Dense(256, activation='relu')(z61)\r\n",
        "    z8 = Dropout(0.5)(z7)\r\n",
        "\r\n",
        "    out = Dense(classes, activation='softmax')(z7)\r\n",
        "\r\n",
        "    y1_pred = Dense(classes, activation='relu', name='output_1')(out)\r\n",
        "    y2_pred = Dense(classes, activation='relu', name='output_2')(out)\r\n",
        "\r\n",
        "    model_input  = Model(inp, [y1_pred, y2_pred])\r\n",
        "\r\n",
        "    # model.summary()\r\n",
        "    # try:\r\n",
        "    #   y1_pred, y2_pred = get_prediction_model(inp, classes)\r\n",
        "    # except Exception as e:\r\n",
        "    #   pass\r\n",
        "    # print(prediction_model(classes))\r\n",
        "    # print(\"AAAAAAAAAAAAAAADDD\")\r\n",
        "    y1_pred, y2_pred = model_input(inp)\r\n",
        "\r\n",
        "    y1_true = Input(shape=(classes,), name='y1_true')\r\n",
        "    # print(y1_true)\r\n",
        "    y2_true = Input(shape=(classes,), name='y2_true')\r\n",
        "    out = CustomMultiLossLayer(nb_outputs=2, name='output_3')([y1_true, y2_true, y1_pred, y2_pred])\r\n",
        "    model = Model([inp, y1_true, y2_true], out)\r\n",
        "\r\n",
        "    # model.summary()\r\n",
        "\r\n",
        "    opt = Adam(lr=learning_rate)\r\n",
        "    # losses = {\r\n",
        "    #   \"output_1\": \"sparse_categorical_crossentropy\",\r\n",
        "    #   \"output_2\": \"poisson\"\r\n",
        "    # }\r\n",
        "    model.compile(optimizer='adam', loss=None)\r\n",
        "\r\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "4eICXNiwGvH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class LSTM_MODEL(object):\r\n",
        "    @staticmethod\r\n",
        "    def build_simple_lstm(data_input_shape, classes, learning_rate):\r\n",
        "        model = Sequential()\r\n",
        "        model.add(CuLSTM(units=128, return_sequences=True, input_shape=data_input_shape))\r\n",
        "        model.add(CuLSTM(units=128,  return_sequences=False))\r\n",
        "        model.add(Dense(units=64, activation=\"relu\"))\r\n",
        "        model.add(Dense(units=classes, activation=\"softmax\"))\r\n",
        "        # Keras optimizer defaults:\r\n",
        "        # Adam   : lr=0.001, beta_1=0.9,  beta_2=0.999, epsilon=1e-8, decay=0.\r\n",
        "        # RMSprop: lr=0.001, rho=0.9,                   epsilon=1e-8, decay=0.\r\n",
        "        # SGD    : lr=0.01,  momentum=0.,                             decay=0.\r\n",
        "        opt = Adam(lr=learning_rate)\r\n",
        "        model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "        return model\r\n",
        "    \r\n",
        "    @staticmethod\r\n",
        "    def build_bilstm(data_input_shape, classes, learning_rate):\r\n",
        "        model = Sequential()\r\n",
        "        model.add(Bidirectional(CuLSTM(128), input_shape=data_input_shape))\r\n",
        "        model.add(Dropout(0.5))\r\n",
        "        model.add(Dense(classes, activation='softmax'))\r\n",
        "        opt = Adam(lr=learning_rate)\r\n",
        "        model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "        # model.summary()\r\n",
        "\r\n",
        "        return model\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def build_residual_bilstm(data_input_shape, classes, learning_rate):\r\n",
        "        inp = Input(shape=data_input_shape)\r\n",
        "\r\n",
        "        # inp = SincConvFast_1(64, 251, sample_frequency)(inp)\r\n",
        "        # inp = normalize(inp)\r\n",
        "        # inp = LayerNormalization()(inp)\r\n",
        "        # inp = SincConvFast(64, 251, sample_frequency)(inp)\r\n",
        "        z1 = Bidirectional(CuLSTM(128, return_sequences=True))(inp)\r\n",
        "        z2 = Bidirectional(CuLSTM(units=128, return_sequences=True))(z1)\r\n",
        "        z3 = add([z1, z2])  # residual connection\r\n",
        "        z4 = Bidirectional(CuLSTM(units=128, return_sequences=True))(z3)\r\n",
        "        z5 = Bidirectional(CuLSTM(units=128, return_sequences=False))(z4)\r\n",
        "        z6 = add([z4, z5])  # residual connection    \r\n",
        "        z61 = Flatten()(z6)        \r\n",
        "        z7 = Dense(256, activation='relu')(z61)\r\n",
        "        z8 = Dropout(0.5)(z7)\r\n",
        "        out = Dense(classes, activation='softmax')(z8)\r\n",
        "        model = Model(inputs=[inp], outputs=out)\r\n",
        "        opt = Adam(lr=learning_rate)\r\n",
        "        model.compile(loss=None, optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "        # model.summary()\r\n",
        "        return model\r\n",
        "    \r\n",
        "    @staticmethod\r\n",
        "    def get_trainable_model(data_input_shape, classes, learning_rate=0.001):\r\n",
        "        # data_input_shape=INPUT_SIZE\r\n",
        "        # classes=N_CLASSES\r\n",
        "        # learning_rate=0.001\r\n",
        "        \r\n",
        "        inp = Input(shape=data_input_shape, name='inp')\r\n",
        "        y1_pred, y2_pred = get_prediction_model(inp)\r\n",
        "        y1_true = Input(shape=(classes,), name='y1_true')\r\n",
        "        y2_true = Input(shape=(classes,), name='y2_true')\r\n",
        "        out = CustomMultiLossLayer(nb_outputs=classes, name='output_3')([y1_true, y2_true, y1_pred, y2_pred])\r\n",
        "        model = Model(inputs=[inp, y1_true, y2_true], outputs=[out, y1_pred, y2_pred])\r\n",
        "        opt = Adam(lr=learning_rate)\r\n",
        "        losses = {\r\n",
        "          \"output_2\": \"sparse_categorical_crossentropy\",\r\n",
        "          \"output_3\": \"poisson\"\r\n",
        "        }\r\n",
        "        model.compile(loss=None, optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "        return model\r\n",
        "\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "hB9Oa9OpPrSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create dataset module"
      ],
      "metadata": {
        "id": "kLAUvlyMP1d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install pydub"
      ],
      "outputs": [],
      "metadata": {
        "id": "XXcKat_R8YrF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import sklearn\r\n",
        "from librosa.util import normalize\r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "from pydub import AudioSegment, effects \r\n",
        "def normalize_manual(x, axis=0):\r\n",
        "    return sklearn.preprocessing.minmax_scale(x, axis=axis)\r\n",
        "\r\n",
        "def normalize_fixed(x, current_range =[[0, 100]], normed_range=[[0, 1]]):\r\n",
        "    current_min, current_max = tf.expand_dims(current_range[:, 0], 1), tf.expand_dims(current_range[:, 1], 1)\r\n",
        "    normed_min, normed_max = tf.expand_dims(normed_range[:, 0], 1), tf.expand_dims(normed_range[:, 1], 1)\r\n",
        "    x_normed = (x - current_min) / (current_max - current_min)\r\n",
        "    x_normed = x_normed * (normed_max - normed_min) + normed_min\r\n",
        "    return x_normed\r\n",
        "\r\n",
        "def despike(yi, th=1.e-8):\r\n",
        "    '''Remove spike from array yi, the spike area is where the difference between the neigboring points is higher than th.'''\r\n",
        "    y = np.copy(yi) # use y = y1 if it is OK to modify input array\r\n",
        "    n = len(y)\r\n",
        "    x = np.arange(n)\r\n",
        "    c = np.argmax(y)\r\n",
        "    d = abs(np.diff(y))\r\n",
        "    try:\r\n",
        "        l = c - 1 - np.where(d[c-1::-1]<th)[0][0]\r\n",
        "        r = c + np.where(d[c:]<th)[0][0] + 1\r\n",
        "    except: # no spike, return unaltered array\r\n",
        "        return y\r\n",
        "    # for fit, use area twice wider then the spike\r\n",
        "    if (r-l) <= 3:\r\n",
        "        l -= 1\r\n",
        "        r += 1\r\n",
        "    s = int(round((r-l)/2.))\r\n",
        "    lx = l - s\r\n",
        "    rx = r + s\r\n",
        "    # make a gap at spike area\r\n",
        "    xgapped = np.concatenate((x[lx:l],x[r:rx]))\r\n",
        "    ygapped = np.concatenate((y[lx:l],y[r:rx]))\r\n",
        "    # quadratic fit of the gapped array\r\n",
        "    z = np.polyfit(xgapped,ygapped,2)\r\n",
        "    p = np.poly1d(z)\r\n",
        "    y[l:r] = p(x[l:r])\r\n",
        "    return y\r\n",
        "\r\n",
        "class BreathDataTrainingGenerator(tf.keras.utils.Sequence):#tensorflow.python.keras.utils.data_utils --- tf.keras.utils.Sequence\r\n",
        "    'Generates data for Keras'\r\n",
        "    def __init__(self, directory, \r\n",
        "                    list_labels=['normal', 'deep', 'heavy', 'other'], \r\n",
        "                    batch_size=32,\r\n",
        "                    dim=None,\r\n",
        "                    classes=None, \r\n",
        "                    shuffle=True):\r\n",
        "        'Initialization'\r\n",
        "        self.directory = directory\r\n",
        "        self.list_labels = list_labels\r\n",
        "        self.dim = dim\r\n",
        "        self.__flow_from_directory(self.directory)\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.classes = len(self.list_labels)\r\n",
        "        self.shuffle = shuffle\r\n",
        "        self.on_epoch_end()\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        'Denotes the number of batches per epoch'\r\n",
        "        return int(np.floor(len(self.wavs) / self.batch_size))\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        # print(\"In get Item!!\")\r\n",
        "        # 'Generate one batch of data'\r\n",
        "        # Generate indexes of the batch\r\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\r\n",
        "\r\n",
        "        # Find list of IDs\r\n",
        "        rawX = [self.wavs[k] for k in indexes]\r\n",
        "        rawY = [self.labels[k] for k in indexes]\r\n",
        "\r\n",
        "        # Generate data\r\n",
        "        X, Y = self.__feature_extraction(rawX, rawY)\r\n",
        "        # print(\"TADDDDDDDD\", len([X, Y, Y]), \" - \", len([X, Y, Y][0]), \" - \", len([X, Y, Y][0][0]))\r\n",
        "        # print(\"Done getting data\")\r\n",
        "        return [X, Y, Y], Y\r\n",
        "\r\n",
        "    def __flow_from_directory(self, directory):\r\n",
        "        self.wavs = []\r\n",
        "        self.labels = []\r\n",
        "        for dir in os.listdir(directory):\r\n",
        "            sub_dir = os.path.join(directory, dir)\r\n",
        "            if os.path.isdir(sub_dir) and dir in self.list_labels:\r\n",
        "                print(sub_dir)\r\n",
        "                label = self.list_labels.index(dir)\r\n",
        "                try:\r\n",
        "                    for file in os.listdir(sub_dir):\r\n",
        "                        if file == '22_male_21_VHung_41_225121_deep.wav':\r\n",
        "                            continue\r\n",
        "                        \r\n",
        "                        self.wavs.append(os.path.join(sub_dir, file))\r\n",
        "                        self.labels.append(label)\r\n",
        "                except Exception as e:\r\n",
        "                    print(e)\r\n",
        "                    print(file)\r\n",
        "                    pass\r\n",
        "\r\n",
        "\r\n",
        "    def on_epoch_end(self):\r\n",
        "        'Updates indexes after each epoch'\r\n",
        "        self.indexes = np.arange(len(self.wavs))\r\n",
        "        if self.shuffle == True:\r\n",
        "            np.random.shuffle(self.indexes)\r\n",
        "\r\n",
        "    def __feature_extraction(self, list_wav, list_label):\r\n",
        "        # print(\"Go to feature extraction!!!\")\r\n",
        "        'Generates data containing batch_size samples'\r\n",
        "        X = []\r\n",
        "        Y = []\r\n",
        "        for i in range(self.batch_size):\r\n",
        "            rate, data = wavfile.read(list_wav[i]) #bug in here\r\n",
        "\r\n",
        "            # data, rate = readCoughData(file=list_wav[i])\r\n",
        "\r\n",
        "\r\n",
        "            # resampledData = resample(originalData=data, origSampFreq=rate, targetSampFreq=16000)\r\n",
        "            # normalizedData = normalizeSound(resampledData, axis=0)\r\n",
        "            # S = calculateMelSpectogram(normalizedData=normalizedData, hop_length=512, win_length=1024, sr=16000)\r\n",
        "            # plotSound(soundData=normalizedData, sr=8000,x_axis_string='time')\r\n",
        "            # plotMelSpectogram(S, sr=8000, ref=np.max)\r\n",
        "\r\n",
        "\r\n",
        "            # data = effects.normalize(data)\r\n",
        "            # print(\"End\")\r\n",
        "            # data = despike(data)\r\n",
        "\r\n",
        "            data = np.array(data, dtype=np.float32)\r\n",
        "            data *= 1./32768\r\n",
        "            # feature = librosa.feature.melspectrogram(y=data, sr=rate, n_fft=2048, hop_length=512, power=2.0)\r\n",
        "            # feature = librosa.feature.rmse(data+ 0.0001)\r\n",
        "            # feature = librosa.feature.spectral_rolloff(y=data, sr=rate)[0]\r\n",
        "            feature = librosa.feature.mfcc(y=data, sr=rate, \r\n",
        "                                           n_mfcc=40, fmin=0, fmax=8000,\r\n",
        "                                           n_fft=int(16*64), hop_length=int(16*32), power=2.0)\r\n",
        "\r\n",
        "            # print(S.shape) # (128, 251)\r\n",
        "            # feature = normalize(feature)\r\n",
        "            feature = np.resize(feature, self.dim)\r\n",
        "\r\n",
        "            # mellog = np.log(feature + 1e-9)\r\n",
        "            # feature = librosa.util.normalize(mellog)\r\n",
        "            # feature= sklearn.preprocessing.normalize(feature)\r\n",
        "\r\n",
        "            # normalize data\r\n",
        "            # feature = normalize(feature)\r\n",
        "\r\n",
        "            category_label =  to_categorical(list_label[i], num_classes= len(self.list_labels) )\r\n",
        "            X.append(feature)\r\n",
        "            Y.append(category_label)\r\n",
        "        \r\n",
        "        # print(X)\r\n",
        "        # X = normalize_fixed(X)\r\n",
        "        # X -= np.mean(X, keepdims=True)\r\n",
        "        # X = (X- np.min(X, 0)) / (np.max(X, 0) + 0.0001) \r\n",
        "        # X /= (np.std(X, keepdims=True) + tf.keras.backend.epsilon())\r\n",
        "        X = np.array(X, dtype=np.float32)\r\n",
        "        mean = np.mean(X, axis=0)\r\n",
        "        std = np.std(X, axis=0)\r\n",
        "\r\n",
        "        X = (X - mean)/std\r\n",
        "\r\n",
        "        # print(len(X[0]))\r\n",
        "        # print(len(X[0][0]))\r\n",
        "\r\n",
        "        # min_max_scaler = preprocessing.MinMaxScaler()\r\n",
        "        \r\n",
        "        Y = np.array(Y, dtype=int)\r\n",
        "        return X, Y\r\n",
        "\r\n",
        "class BreathDataValidationGenerator(tf.keras.utils.Sequence):\r\n",
        "    'Generates data for Keras'\r\n",
        "    def __init__(self, directory, \r\n",
        "                    list_labels=['normal', 'deep', 'heavy', 'other'], \r\n",
        "                    batch_size=32,\r\n",
        "                    dim=None,\r\n",
        "                    classes=None, \r\n",
        "                    shuffle=True):\r\n",
        "        'Initialization'\r\n",
        "        self.directory = directory\r\n",
        "        self.list_labels = list_labels\r\n",
        "        self.dim = dim\r\n",
        "        self.__flow_from_directory(self.directory)\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.classes = len(self.list_labels)\r\n",
        "        self.shuffle = shuffle\r\n",
        "        self.on_epoch_end()\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        'Denotes the number of batches per epoch'\r\n",
        "        return int(np.floor(len(self.wavs) / self.batch_size))\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        # print(\"In get Item!!\")\r\n",
        "        # 'Generate one batch of data'\r\n",
        "        # Generate indexes of the batch\r\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\r\n",
        "\r\n",
        "        # Find list of IDs\r\n",
        "        rawX = [self.wavs[k] for k in indexes]\r\n",
        "        rawY = [self.labels[k] for k in indexes]\r\n",
        "\r\n",
        "        # Generate data\r\n",
        "        X, Y = self.__feature_extraction(rawX, rawY)\r\n",
        "        # print(\"Done getting data\")\r\n",
        "        return X, Y\r\n",
        "\r\n",
        "    def __flow_from_directory(self, directory):\r\n",
        "        self.wavs = []\r\n",
        "        self.labels = []\r\n",
        "        for dir in os.listdir(directory):\r\n",
        "            sub_dir = os.path.join(directory, dir)\r\n",
        "            if os.path.isdir(sub_dir) and dir in self.list_labels:\r\n",
        "                print(sub_dir)\r\n",
        "                label = self.list_labels.index(dir)\r\n",
        "                for file in os.listdir(sub_dir):\r\n",
        "                    self.wavs.append(os.path.join(sub_dir, file))\r\n",
        "                    self.labels.append(label)\r\n",
        "\r\n",
        "    def on_epoch_end(self):\r\n",
        "        'Updates indexes after each epoch'\r\n",
        "        self.indexes = np.arange(len(self.wavs))\r\n",
        "        if self.shuffle == True:\r\n",
        "            np.random.shuffle(self.indexes)\r\n",
        "\r\n",
        "    def __feature_extraction(self, list_wav, list_label):\r\n",
        "        # print(\"Go to feature extraction!!!\")\r\n",
        "        'Generates data containing batch_size samples'\r\n",
        "        X = []\r\n",
        "        Y = []\r\n",
        "        for i in range(self.batch_size):\r\n",
        "            rate, data = wavfile.read(list_wav[i]) #bug in here\r\n",
        "\r\n",
        "            # data, rate = readCoughData(file=list_wav[i])\r\n",
        "\r\n",
        "\r\n",
        "            # resampledData = resample(originalData=data, origSampFreq=rate, targetSampFreq=16000)\r\n",
        "            # normalizedData = normalizeSound(resampledData, axis=0)\r\n",
        "            # S = calculateMelSpectogram(normalizedData=normalizedData, hop_length=512, win_length=1024, sr=16000)\r\n",
        "            # plotSound(soundData=normalizedData, sr=8000,x_axis_string='time')\r\n",
        "            # plotMelSpectogram(S, sr=8000, ref=np.max)\r\n",
        "\r\n",
        "\r\n",
        "            # data = effects.normalize(data)\r\n",
        "            # print(\"End\")\r\n",
        "            # data = despike(data)\r\n",
        "\r\n",
        "            data = np.array(data, dtype=np.float32)\r\n",
        "            data *= 1./32768\r\n",
        "            # feature = librosa.feature.melspectrogram(y=data, sr=rate, n_fft=2048, hop_length=512, power=2.0)\r\n",
        "            # feature = librosa.feature.rmse(data+ 0.0001)\r\n",
        "            # feature = librosa.feature.spectral_rolloff(y=data, sr=rate)[0]\r\n",
        "            feature = librosa.feature.mfcc(y=data, sr=rate, \r\n",
        "                                           n_mfcc=40, fmin=0, fmax=8000,\r\n",
        "                                           n_fft=int(16*64), hop_length=int(16*32), power=2.0)\r\n",
        "\r\n",
        "            # print(S.shape) # (128, 251)\r\n",
        "            # feature = normalize(feature)\r\n",
        "            feature = np.resize(feature, self.dim)\r\n",
        "\r\n",
        "            # mellog = np.log(feature + 1e-9)\r\n",
        "            # feature = librosa.util.normalize(mellog)\r\n",
        "            # feature= sklearn.preprocessing.normalize(feature)\r\n",
        "\r\n",
        "            # normalize data\r\n",
        "            # feature = normalize(feature)\r\n",
        "\r\n",
        "            category_label =  to_categorical(list_label[i], num_classes= len(self.list_labels) )\r\n",
        "            X.append(feature)\r\n",
        "            Y.append(category_label)\r\n",
        "        \r\n",
        "        # print(X)\r\n",
        "        # X = normalize_fixed(X)\r\n",
        "        # X -= np.mean(X, keepdims=True)\r\n",
        "        # X = (X- np.min(X, 0)) / (np.max(X, 0) + 0.0001) \r\n",
        "        # X /= (np.std(X, keepdims=True) + tf.keras.backend.epsilon())\r\n",
        "        X = np.array(X, dtype=np.float32)\r\n",
        "        mean = np.mean(X, axis=0)\r\n",
        "        std = np.std(X, axis=0)\r\n",
        "\r\n",
        "        X = (X - mean)/std\r\n",
        "\r\n",
        "        # print(len(X[0]))\r\n",
        "        # print(len(X[0][0]))\r\n",
        "\r\n",
        "        # min_max_scaler = preprocessing.MinMaxScaler()\r\n",
        "        \r\n",
        "        Y = np.array(Y, dtype=int)\r\n",
        "        return X, Y\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "3vcLMbXwP24B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Constants"
      ],
      "metadata": {
        "id": "EeejFTGQP_MV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Set the config for training\r\n",
        "\r\n",
        "BATCH_SIZE = 32\r\n",
        "# LIST_LABELS = ['normal', 'deep', 'heavy', 'other']\r\n",
        "LIST_LABELS = ['normal', 'deep', 'heavy']\r\n",
        "N_CLASSES = len(LIST_LABELS)\r\n",
        "N_EPOCHS = 100\r\n",
        "\r\n",
        "\r\n",
        "# INPUT_SIZE = (40, 126, 1) # Input size for CNN training\r\n",
        "INPUT_SIZE = (32, 251) # Input size for LSTM training\r\n",
        "\r\n",
        "\r\n",
        "TRAINING_SOURCE = '/content/gdrive/My Drive/Breath-Data/data/training/'\r\n",
        "VALID_SOURCE = '/content/gdrive/My Drive/Breath-Data/data/validation/'\r\n",
        "MODE = 'TRAINING'\r\n",
        "MODEL_OUTPUT = '/content/gdrive/My Drive/Breath-Data/data/model_output'\r\n",
        "\r\n",
        "RUN_TITLE = \"20210706-Residual\""
      ],
      "outputs": [],
      "metadata": {
        "id": "0T9EEg6UP6li"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training model"
      ],
      "metadata": {
        "id": "NAVjPdkxQFyu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Generate data for training\r\n",
        "# try:\r\n",
        "train_generator = BreathDataTrainingGenerator(\r\n",
        "          TRAINING_SOURCE,\r\n",
        "          list_labels=LIST_LABELS,\r\n",
        "          batch_size=BATCH_SIZE,\r\n",
        "          dim=INPUT_SIZE,\r\n",
        "          shuffle=False)\r\n",
        "# except Exception as e:\r\n",
        "#   pass\r\n",
        "\r\n",
        "N_TRAIN_SAMPLES = len(train_generator.wavs)\r\n",
        "print(\"Train samples: {}\".format(N_TRAIN_SAMPLES))\r\n",
        "\r\n",
        "validation_generator = BreathDataTrainingGenerator(\r\n",
        "        VALID_SOURCE,\r\n",
        "        list_labels=LIST_LABELS,\r\n",
        "        batch_size=BATCH_SIZE,\r\n",
        "        dim=INPUT_SIZE,\r\n",
        "        shuffle=False)\r\n",
        "N_VALID_SAMPLES = len(validation_generator.wavs)\r\n",
        "print(\"Validation samples: {}\".format(N_VALID_SAMPLES))\r\n",
        "\r\n",
        "TRAIN_NEW = True\r\n",
        "\r\n",
        "print([train_generator,  np.array(train_generator.classes, dtype=int), np.array(train_generator.classes, dtype=int)])\r\n",
        "\r\n",
        "if TRAIN_NEW:\r\n",
        "\r\n",
        "  # build LSTM model \r\n",
        "\r\n",
        "  # model = LSTM_MODEL.build_simple_lstm(data_input_shape=INPUT_SIZE, classes=N_CLASSES, learning_rate=0.001)\r\n",
        "\r\n",
        "  # model = LSTM_MODEL.build_residual_bilstm(data_input_shape=INPUT_SIZE, classes=N_CLASSES, learning_rate=0.001)\r\n",
        "  # inp = Input(shape=INPUT_SIZE, name='inp')\r\n",
        "  # prediction_model = get_prediction_model(3)\r\n",
        "  # prediction_model.summary()\r\n",
        "  model = get_trainable_model(data_input_shape=INPUT_SIZE, classes=N_CLASSES, learning_rate=0.001)\r\n",
        "\r\n",
        "  # model = LSTM_MODEL.build_seld_net(data_input_shape=INPUT_SIZE, classes=N_CLASSES, learning_rate=0.001)\r\n",
        "\r\n",
        "  # model = LSTM_MODEL.build_bilstm(data_input_shape=INPUT_SIZE, classes=N_CLASSES, learning_rate=0.001)\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "else: \r\n",
        "  from keras.models import load_model\r\n",
        "  # Reload model\r\n",
        "  model = load_model('5S-50-ResidualLSTM-weights-improvement_bi_lstm-30-0.73-0.45.hdf5')\r\n",
        "\r\n",
        "# Checkpoint\r\n",
        "if not os.path.exists(MODEL_OUTPUT):\r\n",
        "    os.makedirs(MODEL_OUTPUT)\r\n",
        "\r\n",
        "epoch = 0\r\n",
        "accuracy = 0.1\r\n",
        "val_accurac = 0.1\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "filepath= os.path.join(MODEL_OUTPUT, RUN_TITLE + \"LSTM-weights-improvement_bi_lstm-{epoch:02d}-{accuracy:.2f}-{val_accuracy:.2f}.hdf5\") \r\n",
        "# filepath=\"./model_output/LSTM-weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\r\n",
        "\r\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', save_best_only=False, mode='max')\r\n",
        "callbacks_list = [checkpoint]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Start training\r\n",
        "model.fit_generator(\r\n",
        "        train_generator,\r\n",
        "        steps_per_epoch= N_TRAIN_SAMPLES // BATCH_SIZE,\r\n",
        "        initial_epoch=0,\r\n",
        "        epochs=N_EPOCHS,\r\n",
        "        validation_data=validation_generator,\r\n",
        "        validation_steps=N_VALID_SAMPLES // BATCH_SIZE,\r\n",
        "        callbacks=callbacks_list,\r\n",
        "        use_multiprocessing=True,\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "YHBujhwbQIX8"
      }
    }
  ]
}